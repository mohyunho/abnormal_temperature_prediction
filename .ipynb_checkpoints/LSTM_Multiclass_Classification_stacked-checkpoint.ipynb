{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nltk version is 3.4.5.\n",
      "The scikit-learn version is 0.21.3.\n",
      "Index(['date', 'temperature'], dtype='object')\n",
      "[      1       2       3 ... 1137599 1137600 1137601]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temperature</th>\n",
       "      <th>cycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-31 00:00:00</td>\n",
       "      <td>19.619791</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-31 00:01:00</td>\n",
       "      <td>18.802944</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-31 00:02:00</td>\n",
       "      <td>19.857184</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2018-01-31 00:03:00</td>\n",
       "      <td>20.208154</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2018-01-31 00:04:00</td>\n",
       "      <td>18.432066</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1137596</td>\n",
       "      <td>2020-03-30 23:56:00</td>\n",
       "      <td>19.419647</td>\n",
       "      <td>1137597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1137597</td>\n",
       "      <td>2020-03-30 23:57:00</td>\n",
       "      <td>19.381692</td>\n",
       "      <td>1137598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1137598</td>\n",
       "      <td>2020-03-30 23:58:00</td>\n",
       "      <td>19.827619</td>\n",
       "      <td>1137599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1137599</td>\n",
       "      <td>2020-03-30 23:59:00</td>\n",
       "      <td>20.136786</td>\n",
       "      <td>1137600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1137600</td>\n",
       "      <td>2020-03-31 00:00:00</td>\n",
       "      <td>20.130036</td>\n",
       "      <td>1137601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1137601 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date  temperature    cycle\n",
       "0       2018-01-31 00:00:00    19.619791        1\n",
       "1       2018-01-31 00:01:00    18.802944        2\n",
       "2       2018-01-31 00:02:00    19.857184        3\n",
       "3       2018-01-31 00:03:00    20.208154        4\n",
       "4       2018-01-31 00:04:00    18.432066        5\n",
       "...                     ...          ...      ...\n",
       "1137596 2020-03-30 23:56:00    19.419647  1137597\n",
       "1137597 2020-03-30 23:57:00    19.381692  1137598\n",
       "1137598 2020-03-30 23:58:00    19.827619  1137599\n",
       "1137599 2020-03-30 23:59:00    20.136786  1137600\n",
       "1137600 2020-03-31 00:00:00    20.130036  1137601\n",
       "\n",
       "[1137601 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import nltk\n",
    "import sklearn\n",
    "# Setting seed for reproducibility\n",
    "np.random.seed(1234)  \n",
    "PYTHONHASHSEED = 0\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "print('The nltk version is {}.'.format(nltk.__version__))\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "## Read csv file of temperature data\n",
    "df_Temp = pd.read_csv('ts_temperature.csv')\n",
    "print (df_Temp.columns)\n",
    "df_Temp['date'] = pd.to_datetime(df_Temp['date'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "# Set index as date\n",
    "# df_Temp = df_Temp.set_index('date')\n",
    "\n",
    "# print (\"type(df_Temp['date'])\", type(df_Temp['date']).__name__)\n",
    "# print (\"type(df_Temp['date'][0])\", type(df_Temp['date'][0]).__name__)\n",
    "\n",
    "#add cycle column to compute RUL and cycle based classification\n",
    "cycle_array = np.arange(len(df_Temp))+1\n",
    "print (cycle_array)\n",
    "\n",
    "df_Temp['cycle'] = cycle_array\n",
    "\n",
    "df_Temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_arr [0 0 0 ... 0 0 0]\n",
      "label_arr ['normal' 'normal' 'normal' ... 'normal' 'normal' 'normal']\n",
      "1132852\n",
      "2425\n",
      "2324\n",
      "bfill abnormal state...\n",
      "fill in residual normal state...\n",
      "                   date  cycle  temperature          label  pad\n",
      "0   2018-01-31 00:00:00      1    19.619791  abnormal(hot)  0.5\n",
      "1   2018-01-31 00:01:00      2    18.802944  abnormal(hot)  0.5\n",
      "2   2018-01-31 00:02:00      3    19.857184  abnormal(hot)  0.5\n",
      "3   2018-01-31 00:03:00      4    20.208154  abnormal(hot)  0.5\n",
      "4   2018-01-31 00:04:00      5    18.432066  abnormal(hot)  0.5\n",
      "5   2018-01-31 00:05:00      6    20.120107  abnormal(hot)  0.5\n",
      "6   2018-01-31 00:06:00      7    19.787803  abnormal(hot)  0.5\n",
      "7   2018-01-31 00:07:00      8    20.353667  abnormal(hot)  0.5\n",
      "8   2018-01-31 00:08:00      9    20.742374  abnormal(hot)  0.5\n",
      "9   2018-01-31 00:09:00     10    19.402086  abnormal(hot)  0.5\n",
      "10  2018-01-31 00:10:00     11    19.689542  abnormal(hot)  0.5\n",
      "11  2018-01-31 00:11:00     12    19.256175  abnormal(hot)  0.5\n",
      "12  2018-01-31 00:12:00     13    20.210760  abnormal(hot)  0.5\n",
      "13  2018-01-31 00:13:00     14    20.721078  abnormal(hot)  0.5\n",
      "14  2018-01-31 00:14:00     15    20.679881  abnormal(hot)  0.5\n",
      "15  2018-01-31 00:15:00     16    19.461181  abnormal(hot)  0.5\n",
      "16  2018-01-31 00:16:00     17    19.664955  abnormal(hot)  0.5\n",
      "17  2018-01-31 00:17:00     18    19.511833  abnormal(hot)  0.5\n",
      "18  2018-01-31 00:18:00     19    18.640298  abnormal(hot)  0.5\n",
      "19  2018-01-31 00:19:00     20    19.858444  abnormal(hot)  0.5\n",
      "20  2018-01-31 00:20:00     21    20.071259  abnormal(hot)  0.5\n",
      "21  2018-01-31 00:21:00     22    19.165832  abnormal(hot)  0.5\n",
      "22  2018-01-31 00:22:00     23    19.965491  abnormal(hot)  0.5\n",
      "23  2018-01-31 00:23:00     24    18.916918  abnormal(hot)  0.5\n",
      "24  2018-01-31 00:24:00     25    19.441630  abnormal(hot)  0.5\n",
      "25  2018-01-31 00:25:00     26    19.789205  abnormal(hot)  0.5\n",
      "26  2018-01-31 00:26:00     27    18.887713  abnormal(hot)  0.5\n",
      "27  2018-01-31 00:27:00     28    19.712152  abnormal(hot)  0.5\n",
      "28  2018-01-31 00:28:00     29    19.440792  abnormal(hot)  0.5\n",
      "29  2018-01-31 00:29:00     30    20.326355  abnormal(hot)  0.5\n",
      "30  2018-01-31 00:30:00     31    19.153188  abnormal(hot)  0.5\n",
      "31  2018-01-31 00:31:00     32    20.227432  abnormal(hot)  0.5\n",
      "32  2018-01-31 00:32:00     33    21.032888  abnormal(hot)  0.5\n",
      "33  2018-01-31 00:33:00     34    22.768475  abnormal(hot)  0.5\n",
      "34  2018-01-31 00:34:00     35    23.860218  abnormal(hot)  0.5\n",
      "35  2018-01-31 00:35:00     36    23.099087  abnormal(hot)  0.5\n",
      "36  2018-01-31 00:36:00     37    23.268100  abnormal(hot)  0.5\n",
      "37  2018-01-31 00:37:00     38    23.251244  abnormal(hot)  0.5\n",
      "38  2018-01-31 00:38:00     39    22.799785  abnormal(hot)  0.5\n",
      "39  2018-01-31 00:39:00     40    23.262836  abnormal(hot)  0.5\n",
      "40  2018-01-31 00:40:00     41    22.689986         normal  0.5\n",
      "41  2018-01-31 00:41:00     42    22.195783         normal  0.5\n",
      "42  2018-01-31 00:42:00     43    22.802077         normal  0.5\n",
      "43  2018-01-31 00:43:00     44    22.336779         normal  0.5\n",
      "44  2018-01-31 00:44:00     45    18.699538         normal  0.5\n",
      "45  2018-01-31 00:45:00     46    19.223113         normal  0.5\n",
      "46  2018-01-31 00:46:00     47    19.997519         normal  0.5\n",
      "47  2018-01-31 00:47:00     48    19.684875         normal  0.5\n",
      "48  2018-01-31 00:48:00     49    19.776850         normal  0.5\n",
      "49  2018-01-31 00:49:00     50    20.062924         normal  0.5\n",
      "50  2018-01-31 00:50:00     51    19.744130         normal  0.5\n",
      "51  2018-01-31 00:51:00     52    20.949080         normal  0.5\n",
      "52  2018-01-31 00:52:00     53    22.093507         normal  0.5\n",
      "53  2018-01-31 00:53:00     54    20.703707         normal  0.5\n",
      "54  2018-01-31 00:54:00     55    21.043162         normal  0.5\n",
      "55  2018-01-31 00:55:00     56    20.639886         normal  0.5\n",
      "56  2018-01-31 00:56:00     57    20.924054         normal  0.5\n",
      "57  2018-01-31 00:57:00     58    20.713282         normal  0.5\n",
      "58  2018-01-31 00:58:00     59    20.352387         normal  0.5\n",
      "59  2018-01-31 00:59:00     60    20.926792         normal  0.5\n",
      "60  2018-01-31 01:00:00     61    20.777575         normal  0.5\n",
      "61  2018-01-31 01:01:00     62    19.925491         normal  0.5\n",
      "62  2018-01-31 01:02:00     63    19.866617         normal  0.5\n",
      "63  2018-01-31 01:03:00     64    20.358960         normal  0.5\n",
      "64  2018-01-31 01:04:00     65    19.111657         normal  0.5\n",
      "65  2018-01-31 01:05:00     66    19.484082         normal  0.5\n",
      "66  2018-01-31 01:06:00     67    20.706520         normal  0.5\n",
      "67  2018-01-31 01:07:00     68    20.171517         normal  0.5\n",
      "68  2018-01-31 01:08:00     69    20.641140         normal  0.5\n",
      "69  2018-01-31 01:09:00     70    20.263254         normal  0.5\n",
      "70  2018-01-31 01:10:00     71    20.180799         normal  0.5\n",
      "71  2018-01-31 01:11:00     72    20.237701         normal  0.5\n",
      "72  2018-01-31 01:12:00     73    19.856391         normal  0.5\n",
      "73  2018-01-31 01:13:00     74    20.969345         normal  0.5\n",
      "74  2018-01-31 01:14:00     75    19.722185         normal  0.5\n",
      "75  2018-01-31 01:15:00     76    20.092500         normal  0.5\n",
      "76  2018-01-31 01:16:00     77    19.522376         normal  0.5\n",
      "77  2018-01-31 01:17:00     78    19.154986         normal  0.5\n",
      "78  2018-01-31 01:18:00     79    19.326212         normal  0.5\n",
      "79  2018-01-31 01:19:00     80    20.746571         normal  0.5\n",
      "80  2018-01-31 01:20:00     81    18.702396         normal  0.5\n",
      "81  2018-01-31 01:21:00     82    18.388740         normal  0.5\n",
      "82  2018-01-31 01:22:00     83    19.437724         normal  0.5\n",
      "83  2018-01-31 01:23:00     84    18.943578         normal  0.5\n",
      "84  2018-01-31 01:24:00     85    19.494355         normal  0.5\n",
      "85  2018-01-31 01:25:00     86    19.484667         normal  0.5\n",
      "86  2018-01-31 01:26:00     87    19.745760         normal  0.5\n",
      "87  2018-01-31 01:27:00     88    19.724688         normal  0.5\n",
      "88  2018-01-31 01:28:00     89    19.574284         normal  0.5\n",
      "89  2018-01-31 01:29:00     90    19.634952         normal  0.5\n",
      "90  2018-01-31 01:30:00     91    18.964060         normal  0.5\n",
      "91  2018-01-31 01:31:00     92    19.651885         normal  0.5\n",
      "92  2018-01-31 01:32:00     93    19.102661         normal  0.5\n",
      "93  2018-01-31 01:33:00     94    19.543213         normal  0.5\n",
      "94  2018-01-31 01:34:00     95    19.669148         normal  0.5\n",
      "95  2018-01-31 01:35:00     96    18.884677         normal  0.5\n",
      "96  2018-01-31 01:36:00     97    19.054579         normal  0.5\n",
      "97  2018-01-31 01:37:00     98    19.100512         normal  0.5\n",
      "98  2018-01-31 01:38:00     99    19.750761         normal  0.5\n",
      "99  2018-01-31 01:39:00    100    20.225685         normal  0.5\n",
      "100 2018-01-31 01:40:00    101    20.202522         normal  0.5\n",
      "101 2018-01-31 01:41:00    102    19.229806         normal  0.5\n",
      "102 2018-01-31 01:42:00    103    19.951938         normal  0.5\n",
      "103 2018-01-31 01:43:00    104    18.468637         normal  0.5\n",
      "104 2018-01-31 01:44:00    105    18.634649         normal  0.5\n",
      "105 2018-01-31 01:45:00    106    19.468277         normal  0.5\n",
      "106 2018-01-31 01:46:00    107    19.172356         normal  0.5\n",
      "107 2018-01-31 01:47:00    108    19.570864         normal  0.5\n",
      "108 2018-01-31 01:48:00    109    19.791700         normal  0.5\n",
      "109 2018-01-31 01:49:00    110    19.589201         normal  0.5\n",
      "110 2018-01-31 01:50:00    111    18.787541         normal  0.5\n",
      "111 2018-01-31 01:51:00    112    18.899947         normal  0.5\n",
      "112 2018-01-31 01:52:00    113    19.008467         normal  0.5\n",
      "113 2018-01-31 01:53:00    114    19.562778         normal  0.5\n",
      "114 2018-01-31 01:54:00    115    19.414424         normal  0.5\n",
      "115 2018-01-31 01:55:00    116    18.966909         normal  0.5\n",
      "116 2018-01-31 01:56:00    117    19.613120         normal  0.5\n",
      "117 2018-01-31 01:57:00    118    19.517996         normal  0.5\n",
      "118 2018-01-31 01:58:00    119    20.618539         normal  0.5\n",
      "119 2018-01-31 01:59:00    120    19.530751         normal  0.5\n",
      "120 2018-01-31 02:00:00    121    19.873905         normal  0.5\n",
      "121 2018-01-31 02:01:00    122    19.799265         normal  0.5\n",
      "122 2018-01-31 02:02:00    123    19.320580         normal  0.5\n",
      "123 2018-01-31 02:03:00    124    19.834162         normal  0.5\n",
      "124 2018-01-31 02:04:00    125    20.951582         normal  0.5\n",
      "125 2018-01-31 02:05:00    126    19.983169         normal  0.5\n",
      "126 2018-01-31 02:06:00    127    20.006215         normal  0.5\n",
      "127 2018-01-31 02:07:00    128    20.609330         normal  0.5\n",
      "128 2018-01-31 02:08:00    129    20.431143         normal  0.5\n",
      "129 2018-01-31 02:09:00    130    19.854568         normal  0.5\n",
      "130 2018-01-31 02:10:00    131    17.552642         normal  0.5\n",
      "131 2018-01-31 02:11:00    132    20.712775         normal  0.5\n",
      "132 2018-01-31 02:12:00    133    19.568466         normal  0.5\n",
      "133 2018-01-31 02:13:00    134    20.482124         normal  0.5\n",
      "134 2018-01-31 02:14:00    135    20.347050         normal  0.5\n",
      "135 2018-01-31 02:15:00    136    18.530732         normal  0.5\n",
      "136 2018-01-31 02:16:00    137    20.231790         normal  0.5\n",
      "137 2018-01-31 02:17:00    138    20.219884         normal  0.5\n",
      "138 2018-01-31 02:18:00    139    20.246352         normal  0.5\n",
      "139 2018-01-31 02:19:00    140    19.147922         normal  0.5\n",
      "140 2018-01-31 02:20:00    141    20.241603         normal  0.5\n",
      "141 2018-01-31 02:21:00    142    19.145996         normal  0.5\n",
      "142 2018-01-31 02:22:00    143    20.433435         normal  0.5\n",
      "143 2018-01-31 02:23:00    144    20.029563         normal  0.5\n",
      "144 2018-01-31 02:24:00    145    20.505954         normal  0.5\n",
      "145 2018-01-31 02:25:00    146    19.536853         normal  0.5\n",
      "146 2018-01-31 02:26:00    147    19.840481         normal  0.5\n",
      "147 2018-01-31 02:27:00    148    19.455246         normal  0.5\n",
      "148 2018-01-31 02:28:00    149    19.012393         normal  0.5\n",
      "149 2018-01-31 02:29:00    150    19.349497         normal  0.5\n",
      "150 2018-01-31 02:30:00    151    19.713592         normal  0.5\n",
      "151 2018-01-31 02:31:00    152    19.345205         normal  0.5\n",
      "152 2018-01-31 02:32:00    153    20.339298         normal  0.5\n",
      "153 2018-01-31 02:33:00    154    19.430391         normal  0.5\n",
      "154 2018-01-31 02:34:00    155    19.222645         normal  0.5\n",
      "155 2018-01-31 02:35:00    156    20.070957         normal  0.5\n",
      "156 2018-01-31 02:36:00    157    19.205767         normal  0.5\n",
      "157 2018-01-31 02:37:00    158    19.614275         normal  0.5\n",
      "158 2018-01-31 02:38:00    159    19.929125         normal  0.5\n",
      "159 2018-01-31 02:39:00    160    19.821841         normal  0.5\n",
      "160 2018-01-31 02:40:00    161    19.989400         normal  0.5\n",
      "161 2018-01-31 02:41:00    162    19.985744         normal  0.5\n",
      "162 2018-01-31 02:42:00    163    19.480668         normal  0.5\n",
      "163 2018-01-31 02:43:00    164    20.116728         normal  0.5\n",
      "164 2018-01-31 02:44:00    165    19.355040         normal  0.5\n",
      "165 2018-01-31 02:45:00    166    21.156695         normal  0.5\n",
      "166 2018-01-31 02:46:00    167    19.739616         normal  0.5\n",
      "167 2018-01-31 02:47:00    168    19.810316         normal  0.5\n",
      "168 2018-01-31 02:48:00    169    20.003679         normal  0.5\n",
      "169 2018-01-31 02:49:00    170    19.985290         normal  0.5\n",
      "170 2018-01-31 02:50:00    171    20.140964         normal  0.5\n",
      "171 2018-01-31 02:51:00    172    19.892723         normal  0.5\n",
      "172 2018-01-31 02:52:00    173    20.104938         normal  0.5\n",
      "173 2018-01-31 02:53:00    174    20.262881         normal  0.5\n",
      "174 2018-01-31 02:54:00    175    20.383785         normal  0.5\n",
      "175 2018-01-31 02:55:00    176    19.903683         normal  0.5\n",
      "176 2018-01-31 02:56:00    177    18.936421         normal  0.5\n",
      "177 2018-01-31 02:57:00    178    19.287868         normal  0.5\n",
      "178 2018-01-31 02:58:00    179    20.184013         normal  0.5\n",
      "179 2018-01-31 02:59:00    180    20.610021         normal  0.5\n",
      "180 2018-01-31 03:00:00    181    20.220918         normal  0.5\n",
      "181 2018-01-31 03:01:00    182    20.806706         normal  0.5\n",
      "182 2018-01-31 03:02:00    183    20.342217         normal  0.5\n",
      "183 2018-01-31 03:03:00    184    20.471516         normal  0.5\n",
      "184 2018-01-31 03:04:00    185    20.255186         normal  0.5\n",
      "185 2018-01-31 03:05:00    186    19.879106         normal  0.5\n",
      "186 2018-01-31 03:06:00    187    20.642396         normal  0.5\n",
      "187 2018-01-31 03:07:00    188    19.640035         normal  0.5\n",
      "188 2018-01-31 03:08:00    189    20.166438         normal  0.5\n",
      "189 2018-01-31 03:09:00    190    19.301164         normal  0.5\n",
      "190 2018-01-31 03:10:00    191    20.266737         normal  0.5\n",
      "191 2018-01-31 03:11:00    192    19.597343         normal  0.5\n",
      "192 2018-01-31 03:12:00    193    19.139218         normal  0.5\n",
      "193 2018-01-31 03:13:00    194    19.215911         normal  0.5\n",
      "194 2018-01-31 03:14:00    195    18.978933         normal  0.5\n",
      "195 2018-01-31 03:15:00    196    18.405305         normal  0.5\n",
      "196 2018-01-31 03:16:00    197    19.317677         normal  0.5\n",
      "197 2018-01-31 03:17:00    198    18.166120         normal  0.5\n",
      "198 2018-01-31 03:18:00    199    19.828026         normal  0.5\n",
      "199 2018-01-31 03:19:00    200    19.601784         normal  0.5\n",
      "200 2018-01-31 03:20:00    201    19.797269         normal  0.5\n",
      "201 2018-01-31 03:21:00    202    19.565711         normal  0.5\n",
      "202 2018-01-31 03:22:00    203    20.586715         normal  0.5\n",
      "203 2018-01-31 03:23:00    204    18.874617         normal  0.5\n",
      "204 2018-01-31 03:24:00    205    18.894610         normal  0.5\n",
      "205 2018-01-31 03:25:00    206    19.923823         normal  0.5\n",
      "206 2018-01-31 03:26:00    207    20.189816         normal  0.5\n",
      "207 2018-01-31 03:27:00    208    19.371493         normal  0.5\n",
      "208 2018-01-31 03:28:00    209    19.943008         normal  0.5\n",
      "209 2018-01-31 03:29:00    210    19.706903         normal  0.5\n",
      "210 2018-01-31 03:30:00    211    19.573737         normal  0.5\n",
      "211 2018-01-31 03:31:00    212    19.598404         normal  0.5\n",
      "212 2018-01-31 03:32:00    213    20.040095         normal  0.5\n",
      "213 2018-01-31 03:33:00    214    20.011142         normal  0.5\n",
      "214 2018-01-31 03:34:00    215    19.768721         normal  0.5\n",
      "215 2018-01-31 03:35:00    216    19.448550         normal  0.5\n",
      "216 2018-01-31 03:36:00    217    20.436356         normal  0.5\n",
      "217 2018-01-31 03:37:00    218    20.308147         normal  0.5\n",
      "218 2018-01-31 03:38:00    219    20.451009         normal  0.5\n",
      "219 2018-01-31 03:39:00    220    17.718272         normal  0.5\n",
      "220 2018-01-31 03:40:00    221    17.843681         normal  0.5\n",
      "221 2018-01-31 03:41:00    222    18.415465         normal  0.5\n",
      "222 2018-01-31 03:42:00    223    17.761922         normal  0.5\n",
      "223 2018-01-31 03:43:00    224    18.143689         normal  0.5\n",
      "224 2018-01-31 03:44:00    225    17.123661         normal  0.5\n",
      "225 2018-01-31 03:45:00    226    17.929911         normal  0.5\n",
      "226 2018-01-31 03:46:00    227    18.010050         normal  0.5\n",
      "227 2018-01-31 03:47:00    228    17.295186         normal  0.5\n",
      "228 2018-01-31 03:48:00    229    19.572032         normal  0.5\n",
      "229 2018-01-31 03:49:00    230    20.269717         normal  0.5\n",
      "230 2018-01-31 03:50:00    231    18.810837         normal  0.5\n",
      "231 2018-01-31 03:51:00    232    17.984615         normal  0.5\n",
      "232 2018-01-31 03:52:00    233    18.291078         normal  0.5\n",
      "233 2018-01-31 03:53:00    234    19.358859         normal  0.5\n",
      "234 2018-01-31 03:54:00    235    18.406982         normal  0.5\n",
      "235 2018-01-31 03:55:00    236    19.292881         normal  0.5\n",
      "236 2018-01-31 03:56:00    237    19.299335         normal  0.5\n",
      "237 2018-01-31 03:57:00    238    18.437289         normal  0.5\n",
      "238 2018-01-31 03:58:00    239    18.669273         normal  0.5\n",
      "239 2018-01-31 03:59:00    240    18.308502         normal  0.5\n",
      "240 2018-01-31 04:00:00    241    17.788311         normal  0.5\n",
      "241 2018-01-31 04:01:00    242    18.343633         normal  0.5\n",
      "242 2018-01-31 04:02:00    243    18.380519         normal  0.5\n",
      "243 2018-01-31 04:03:00    244    18.036718         normal  0.5\n",
      "244 2018-01-31 04:04:00    245    17.723718         normal  0.5\n",
      "245 2018-01-31 04:05:00    246    19.452567         normal  0.5\n",
      "246 2018-01-31 04:06:00    247    20.008210         normal  0.5\n",
      "247 2018-01-31 04:07:00    248    20.509774         normal  0.5\n",
      "248 2018-01-31 04:08:00    249    20.500958         normal  0.5\n",
      "249 2018-01-31 04:09:00    250    20.048424         normal  0.5\n",
      "250 2018-01-31 04:10:00    251    19.619348         normal  0.5\n",
      "251 2018-01-31 04:11:00    252    20.127348         normal  0.5\n",
      "252 2018-01-31 04:12:00    253    20.581432         normal  0.5\n",
      "253 2018-01-31 04:13:00    254    20.406092         normal  0.5\n",
      "254 2018-01-31 04:14:00    255    19.836158         normal  0.5\n",
      "255 2018-01-31 04:15:00    256    20.605528         normal  0.5\n",
      "256 2018-01-31 04:16:00    257    20.086963         normal  0.5\n",
      "257 2018-01-31 04:17:00    258    20.054975         normal  0.5\n",
      "258 2018-01-31 04:18:00    259    19.693045         normal  0.5\n",
      "259 2018-01-31 04:19:00    260    19.968357         normal  0.5\n",
      "260 2018-01-31 04:20:00    261    19.894719         normal  0.5\n",
      "261 2018-01-31 04:21:00    262    19.686590         normal  0.5\n",
      "262 2018-01-31 04:22:00    263    20.607374         normal  0.5\n",
      "263 2018-01-31 04:23:00    264    20.503105         normal  0.5\n",
      "264 2018-01-31 04:24:00    265    19.738798         normal  0.5\n",
      "265 2018-01-31 04:25:00    266    22.699836         normal  0.5\n",
      "266 2018-01-31 04:26:00    267    21.965973         normal  0.5\n",
      "267 2018-01-31 04:27:00    268    21.586617         normal  0.5\n",
      "268 2018-01-31 04:28:00    269    22.623165         normal  0.5\n",
      "269 2018-01-31 04:29:00    270    20.853877         normal  0.5\n",
      "270 2018-01-31 04:30:00    271    21.643389         normal  0.5\n",
      "271 2018-01-31 04:31:00    272    20.999904         normal  0.5\n",
      "272 2018-01-31 04:32:00    273    20.522012         normal  0.5\n",
      "273 2018-01-31 04:33:00    274    20.924532         normal  0.5\n",
      "274 2018-01-31 04:34:00    275    20.165162         normal  0.5\n",
      "275 2018-01-31 04:35:00    276    18.857857         normal  0.5\n",
      "276 2018-01-31 04:36:00    277    20.499187         normal  0.5\n",
      "277 2018-01-31 04:37:00    278    20.389028         normal  0.5\n",
      "278 2018-01-31 04:38:00    279    20.027060         normal  0.5\n",
      "279 2018-01-31 04:39:00    280    20.201053         normal  0.5\n",
      "280 2018-01-31 04:40:00    281    19.003543         normal  0.5\n",
      "281 2018-01-31 04:41:00    282    19.193349         normal  0.5\n",
      "282 2018-01-31 04:42:00    283    20.184252         normal  0.5\n",
      "283 2018-01-31 04:43:00    284    19.985835         normal  0.5\n",
      "284 2018-01-31 04:44:00    285    19.348026         normal  0.5\n",
      "285 2018-01-31 04:45:00    286    19.519420         normal  0.5\n",
      "286 2018-01-31 04:46:00    287    19.119062         normal  0.5\n",
      "287 2018-01-31 04:47:00    288    19.691543         normal  0.5\n",
      "288 2018-01-31 04:48:00    289    20.284026         normal  0.5\n",
      "289 2018-01-31 04:49:00    290    19.428753         normal  0.5\n",
      "290 2018-01-31 04:50:00    291    20.379859         normal  0.5\n",
      "291 2018-01-31 04:51:00    292    19.786919         normal  0.5\n",
      "292 2018-01-31 04:52:00    293    18.606799         normal  0.5\n",
      "293 2018-01-31 04:53:00    294    20.716660         normal  0.5\n",
      "294 2018-01-31 04:54:00    295    19.504543         normal  0.5\n",
      "295 2018-01-31 04:55:00    296    19.809291         normal  0.5\n",
      "296 2018-01-31 04:56:00    297    19.727464         normal  0.5\n",
      "297 2018-01-31 04:57:00    298    19.333666         normal  0.5\n",
      "298 2018-01-31 04:58:00    299    19.731290         normal  0.5\n",
      "299 2018-01-31 04:59:00    300    18.960832         normal  0.5\n",
      "300 2018-01-31 05:00:00    301    19.692245         normal  0.5\n",
      "301 2018-01-31 05:01:00    302    20.203403         normal  0.5\n",
      "302 2018-01-31 05:02:00    303    20.105859         normal  0.5\n",
      "303 2018-01-31 05:03:00    304    19.683731         normal  0.5\n",
      "304 2018-01-31 05:04:00    305    20.683089         normal  0.5\n",
      "305 2018-01-31 05:05:00    306    19.600444         normal  0.5\n",
      "306 2018-01-31 05:06:00    307    20.248598         normal  0.5\n",
      "307 2018-01-31 05:07:00    308    19.250822         normal  0.5\n",
      "308 2018-01-31 05:08:00    309    20.131414         normal  0.5\n",
      "309 2018-01-31 05:09:00    310    19.195888         normal  0.5\n",
      "310 2018-01-31 05:10:00    311    19.649925         normal  0.5\n",
      "311 2018-01-31 05:11:00    312    19.207434         normal  0.5\n",
      "312 2018-01-31 05:12:00    313    20.152828         normal  0.5\n",
      "313 2018-01-31 05:13:00    314    19.458274         normal  0.5\n",
      "314 2018-01-31 05:14:00    315    19.518545         normal  0.5\n",
      "315 2018-01-31 05:15:00    316    20.308354         normal  0.5\n",
      "316 2018-01-31 05:16:00    317    20.354539         normal  0.5\n",
      "317 2018-01-31 05:17:00    318    19.197966         normal  0.5\n",
      "318 2018-01-31 05:18:00    319    19.887953         normal  0.5\n",
      "319 2018-01-31 05:19:00    320    20.879879         normal  0.5\n",
      "320 2018-01-31 05:20:00    321    19.449314         normal  0.5\n",
      "321 2018-01-31 05:21:00    322    19.438938         normal  0.5\n",
      "322 2018-01-31 05:22:00    323    19.818746         normal  0.5\n",
      "323 2018-01-31 05:23:00    324    20.313617         normal  0.5\n",
      "324 2018-01-31 05:24:00    325    20.257196         normal  0.5\n",
      "325 2018-01-31 05:25:00    326    19.578247         normal  0.5\n",
      "326 2018-01-31 05:26:00    327    20.254040         normal  0.5\n",
      "327 2018-01-31 05:27:00    328    20.671734         normal  0.5\n",
      "328 2018-01-31 05:28:00    329    19.977690         normal  0.5\n",
      "329 2018-01-31 05:29:00    330    20.818778         normal  0.5\n",
      "330 2018-01-31 05:30:00    331    19.901853         normal  0.5\n",
      "331 2018-01-31 05:31:00    332    19.294276         normal  0.5\n",
      "332 2018-01-31 05:32:00    333    19.775652         normal  0.5\n",
      "333 2018-01-31 05:33:00    334    19.357370         normal  0.5\n",
      "334 2018-01-31 05:34:00    335    20.436048         normal  0.5\n",
      "335 2018-01-31 05:35:00    336    19.616730         normal  0.5\n",
      "336 2018-01-31 05:36:00    337    19.602313         normal  0.5\n",
      "337 2018-01-31 05:37:00    338    19.917573         normal  0.5\n",
      "338 2018-01-31 05:38:00    339    21.057124         normal  0.5\n",
      "339 2018-01-31 05:39:00    340    21.237080         normal  0.5\n",
      "340 2018-01-31 05:40:00    341    21.358096         normal  0.5\n",
      "341 2018-01-31 05:41:00    342    20.762497         normal  0.5\n",
      "342 2018-01-31 05:42:00    343    20.508420         normal  0.5\n",
      "343 2018-01-31 05:43:00    344    21.270965         normal  0.5\n",
      "344 2018-01-31 05:44:00    345    20.096235         normal  0.5\n",
      "345 2018-01-31 05:45:00    346    20.580161         normal  0.5\n",
      "346 2018-01-31 05:46:00    347    20.807637         normal  0.5\n",
      "347 2018-01-31 05:47:00    348    21.498795         normal  0.5\n",
      "348 2018-01-31 05:48:00    349    21.349792         normal  0.5\n",
      "349 2018-01-31 05:49:00    350    20.694413         normal  0.5\n",
      "350 2018-01-31 05:50:00    351    21.252035         normal  0.5\n",
      "351 2018-01-31 05:51:00    352    20.972110         normal  0.5\n",
      "352 2018-01-31 05:52:00    353    21.198360         normal  0.5\n",
      "353 2018-01-31 05:53:00    354    19.802051         normal  0.5\n",
      "354 2018-01-31 05:54:00    355    19.277199         normal  0.5\n",
      "355 2018-01-31 05:55:00    356    20.077978         normal  0.5\n",
      "356 2018-01-31 05:56:00    357    20.094006         normal  0.5\n",
      "357 2018-01-31 05:57:00    358    20.438134         normal  0.5\n",
      "358 2018-01-31 05:58:00    359    20.204200         normal  0.5\n",
      "359 2018-01-31 05:59:00    360    20.384151         normal  0.5\n",
      "360 2018-01-31 06:00:00    361    19.035915         normal  0.5\n",
      "361 2018-01-31 06:01:00    362    19.583125         normal  0.5\n",
      "362 2018-01-31 06:02:00    363    19.700093         normal  0.5\n",
      "363 2018-01-31 06:03:00    364    20.174239         normal  0.5\n",
      "364 2018-01-31 06:04:00    365    19.193228         normal  0.5\n",
      "365 2018-01-31 06:05:00    366    20.182024         normal  0.5\n",
      "366 2018-01-31 06:06:00    367    19.842987         normal  0.5\n",
      "367 2018-01-31 06:07:00    368    20.171373         normal  0.5\n",
      "368 2018-01-31 06:08:00    369    20.101734         normal  0.5\n",
      "369 2018-01-31 06:09:00    370    19.848395         normal  0.5\n",
      "370 2018-01-31 06:10:00    371    19.468584         normal  0.5\n",
      "371 2018-01-31 06:11:00    372    19.317834         normal  0.5\n",
      "372 2018-01-31 06:12:00    373    19.896351         normal  0.5\n",
      "373 2018-01-31 06:13:00    374    19.633842         normal  0.5\n",
      "374 2018-01-31 06:14:00    375    20.221877         normal  0.5\n",
      "375 2018-01-31 06:15:00    376    20.160907         normal  0.5\n",
      "376 2018-01-31 06:16:00    377    19.114794         normal  0.5\n",
      "377 2018-01-31 06:17:00    378    20.359707         normal  0.5\n",
      "378 2018-01-31 06:18:00    379    19.731975         normal  0.5\n",
      "379 2018-01-31 06:19:00    380    19.780515         normal  0.5\n",
      "380 2018-01-31 06:20:00    381    19.904728         normal  0.5\n",
      "381 2018-01-31 06:21:00    382    20.633597         normal  0.5\n",
      "382 2018-01-31 06:22:00    383    19.335834         normal  0.5\n",
      "383 2018-01-31 06:23:00    384    20.233947         normal  0.5\n",
      "384 2018-01-31 06:24:00    385    20.398794         normal  0.5\n",
      "385 2018-01-31 06:25:00    386    20.127701         normal  0.5\n",
      "386 2018-01-31 06:26:00    387    19.358797         normal  0.5\n",
      "387 2018-01-31 06:27:00    388    20.486816         normal  0.5\n",
      "388 2018-01-31 06:28:00    389    20.438860         normal  0.5\n",
      "389 2018-01-31 06:29:00    390    20.408265         normal  0.5\n",
      "390 2018-01-31 06:30:00    391    19.995700         normal  0.5\n",
      "391 2018-01-31 06:31:00    392    19.929468         normal  0.5\n",
      "392 2018-01-31 06:32:00    393    21.598481         normal  0.5\n",
      "393 2018-01-31 06:33:00    394    19.832566         normal  0.5\n",
      "394 2018-01-31 06:34:00    395    20.473444         normal  0.5\n",
      "395 2018-01-31 06:35:00    396    21.006978         normal  0.5\n",
      "396 2018-01-31 06:36:00    397    19.577635         normal  0.5\n",
      "397 2018-01-31 06:37:00    398    18.158613         normal  0.5\n",
      "398 2018-01-31 06:38:00    399    20.269812         normal  0.5\n",
      "399 2018-01-31 06:39:00    400    19.749202         normal  0.5\n",
      "400 2018-01-31 06:40:00    401    19.490341         normal  0.5\n",
      "401 2018-01-31 06:41:00    402    18.920723         normal  0.5\n",
      "402 2018-01-31 06:42:00    403    20.116738         normal  0.5\n",
      "403 2018-01-31 06:43:00    404    20.516517         normal  0.5\n",
      "404 2018-01-31 06:44:00    405    19.295053         normal  0.5\n",
      "405 2018-01-31 06:45:00    406    20.404687         normal  0.5\n",
      "406 2018-01-31 06:46:00    407    19.585789         normal  0.5\n",
      "407 2018-01-31 06:47:00    408    19.436638         normal  0.5\n",
      "408 2018-01-31 06:48:00    409    19.645708         normal  0.5\n",
      "409 2018-01-31 06:49:00    410    19.576862         normal  0.5\n",
      "410 2018-01-31 06:50:00    411    18.878069         normal  0.5\n",
      "411 2018-01-31 06:51:00    412    18.791935         normal  0.5\n",
      "412 2018-01-31 06:52:00    413    19.394145         normal  0.5\n",
      "413 2018-01-31 06:53:00    414    19.750076         normal  0.5\n",
      "414 2018-01-31 06:54:00    415    18.888537         normal  0.5\n",
      "415 2018-01-31 06:55:00    416    18.941559         normal  0.5\n",
      "416 2018-01-31 06:56:00    417    19.874586         normal  0.5\n",
      "417 2018-01-31 06:57:00    418    20.473008         normal  0.5\n",
      "418 2018-01-31 06:58:00    419    20.059885         normal  0.5\n",
      "419 2018-01-31 06:59:00    420    19.728888         normal  0.5\n",
      "420 2018-01-31 07:00:00    421    20.605067         normal  0.5\n",
      "421 2018-01-31 07:01:00    422    19.951092         normal  0.5\n",
      "422 2018-01-31 07:02:00    423    20.226979         normal  0.5\n",
      "423 2018-01-31 07:03:00    424    19.699861         normal  0.5\n",
      "424 2018-01-31 07:04:00    425    19.157153         normal  0.5\n",
      "425 2018-01-31 07:05:00    426    19.675263         normal  0.5\n",
      "426 2018-01-31 07:06:00    427    19.340419         normal  0.5\n",
      "427 2018-01-31 07:07:00    428    18.808249         normal  0.5\n",
      "428 2018-01-31 07:08:00    429    19.553786         normal  0.5\n",
      "429 2018-01-31 07:09:00    430    20.781137         normal  0.5\n",
      "430 2018-01-31 07:10:00    431    18.903733         normal  0.5\n",
      "431 2018-01-31 07:11:00    432    18.460340         normal  0.5\n",
      "432 2018-01-31 07:12:00    433    19.182568         normal  0.5\n",
      "433 2018-01-31 07:13:00    434    18.990238         normal  0.5\n",
      "434 2018-01-31 07:14:00    435    18.077728         normal  0.5\n",
      "435 2018-01-31 07:15:00    436    18.709878         normal  0.5\n",
      "436 2018-01-31 07:16:00    437    19.317535         normal  0.5\n",
      "437 2018-01-31 07:17:00    438    18.602981         normal  0.5\n",
      "438 2018-01-31 07:18:00    439    18.906844         normal  0.5\n",
      "439 2018-01-31 07:19:00    440    19.444638         normal  0.5\n",
      "440 2018-01-31 07:20:00    441    18.516039         normal  0.5\n",
      "441 2018-01-31 07:21:00    442    18.236876         normal  0.5\n",
      "442 2018-01-31 07:22:00    443    18.952923         normal  0.5\n",
      "443 2018-01-31 07:23:00    444    18.585058         normal  0.5\n",
      "444 2018-01-31 07:24:00    445    19.512623         normal  0.5\n",
      "445 2018-01-31 07:25:00    446    19.307753         normal  0.5\n",
      "446 2018-01-31 07:26:00    447    19.117376         normal  0.5\n",
      "447 2018-01-31 07:27:00    448    19.170212         normal  0.5\n",
      "448 2018-01-31 07:28:00    449    19.397272         normal  0.5\n",
      "449 2018-01-31 07:29:00    450    18.331229         normal  0.5\n",
      "450 2018-01-31 07:30:00    451    20.688199         normal  0.5\n",
      "451 2018-01-31 07:31:00    452    19.612701         normal  0.5\n",
      "452 2018-01-31 07:32:00    453    20.233182         normal  0.5\n",
      "453 2018-01-31 07:33:00    454    20.933201         normal  0.5\n",
      "454 2018-01-31 07:34:00    455    19.848876         normal  0.5\n",
      "455 2018-01-31 07:35:00    456    20.510992         normal  0.5\n",
      "456 2018-01-31 07:36:00    457    20.208258         normal  0.5\n",
      "457 2018-01-31 07:37:00    458    19.587812         normal  0.5\n",
      "458 2018-01-31 07:38:00    459    19.778509         normal  0.5\n",
      "459 2018-01-31 07:39:00    460    20.305598         normal  0.5\n",
      "460 2018-01-31 07:40:00    461    20.204411         normal  0.5\n",
      "461 2018-01-31 07:41:00    462    20.618001         normal  0.5\n",
      "462 2018-01-31 07:42:00    463    19.207923         normal  0.5\n",
      "463 2018-01-31 07:43:00    464    20.294509         normal  0.5\n",
      "464 2018-01-31 07:44:00    465    20.409160         normal  0.5\n",
      "465 2018-01-31 07:45:00    466    19.696109         normal  0.5\n",
      "466 2018-01-31 07:46:00    467    19.789954         normal  0.5\n",
      "467 2018-01-31 07:47:00    468    20.392367         normal  0.5\n",
      "468 2018-01-31 07:48:00    469    20.031798         normal  0.5\n",
      "469 2018-01-31 07:49:00    470    19.727610         normal  0.5\n",
      "470 2018-01-31 07:50:00    471    20.009183         normal  0.5\n",
      "471 2018-01-31 07:51:00    472    19.789605         normal  0.5\n",
      "472 2018-01-31 07:52:00    473    19.746704         normal  0.5\n",
      "473 2018-01-31 07:53:00    474    19.722819         normal  0.5\n",
      "474 2018-01-31 07:54:00    475    20.151695         normal  0.5\n",
      "475 2018-01-31 07:55:00    476    19.744469         normal  0.5\n",
      "476 2018-01-31 07:56:00    477    18.994273         normal  0.5\n",
      "477 2018-01-31 07:57:00    478    19.751230         normal  0.5\n",
      "478 2018-01-31 07:58:00    479    19.596278         normal  0.5\n",
      "479 2018-01-31 07:59:00    480    19.395625         normal  0.5\n",
      "480 2018-01-31 08:00:00    481    19.449539         normal  0.5\n",
      "481 2018-01-31 08:01:00    482    19.845635         normal  0.5\n",
      "482 2018-01-31 08:02:00    483    19.516985         normal  0.5\n",
      "483 2018-01-31 08:03:00    484    19.180553         normal  0.5\n",
      "484 2018-01-31 08:04:00    485    19.285106         normal  0.5\n",
      "485 2018-01-31 08:05:00    486    19.360366         normal  0.5\n",
      "486 2018-01-31 08:06:00    487    20.564269         normal  0.5\n",
      "487 2018-01-31 08:07:00    488    20.597076         normal  0.5\n",
      "488 2018-01-31 08:08:00    489    19.686242         normal  0.5\n",
      "489 2018-01-31 08:09:00    490    19.479149         normal  0.5\n",
      "490 2018-01-31 08:10:00    491    18.988635         normal  0.5\n",
      "491 2018-01-31 08:11:00    492    20.227783         normal  0.5\n",
      "492 2018-01-31 08:12:00    493    19.762490         normal  0.5\n",
      "493 2018-01-31 08:13:00    494    21.030350         normal  0.5\n",
      "494 2018-01-31 08:14:00    495    19.228316         normal  0.5\n",
      "495 2018-01-31 08:15:00    496    20.064032         normal  0.5\n",
      "496 2018-01-31 08:16:00    497    20.301650         normal  0.5\n",
      "497 2018-01-31 08:17:00    498    21.180384         normal  0.5\n",
      "498 2018-01-31 08:18:00    499    20.616385         normal  0.5\n",
      "499 2018-01-31 08:19:00    500    20.826926         normal  0.5\n",
      "500 2018-01-31 08:20:00    501    19.552705         normal  0.5\n",
      "501 2018-01-31 08:21:00    502    19.551038         normal  0.5\n",
      "502 2018-01-31 08:22:00    503    20.306386         normal  0.5\n",
      "503 2018-01-31 08:23:00    504    20.874006         normal  0.5\n",
      "504 2018-01-31 08:24:00    505    19.976110         normal  0.5\n",
      "505 2018-01-31 08:25:00    506    19.404371         normal  0.5\n",
      "506 2018-01-31 08:26:00    507    19.872949         normal  0.5\n",
      "507 2018-01-31 08:27:00    508    20.114995         normal  0.5\n",
      "508 2018-01-31 08:28:00    509    20.359374         normal  0.5\n",
      "509 2018-01-31 08:29:00    510    20.517072         normal  0.5\n",
      "510 2018-01-31 08:30:00    511    19.792295         normal  0.5\n",
      "511 2018-01-31 08:31:00    512    19.530401         normal  0.5\n",
      "512 2018-01-31 08:32:00    513    20.515044         normal  0.5\n",
      "513 2018-01-31 08:33:00    514    19.288366         normal  0.5\n",
      "514 2018-01-31 08:34:00    515    18.545619         normal  0.5\n",
      "515 2018-01-31 08:35:00    516    20.369657         normal  0.5\n",
      "516 2018-01-31 08:36:00    517    20.247275         normal  0.5\n",
      "517 2018-01-31 08:37:00    518    19.689185         normal  0.5\n",
      "518 2018-01-31 08:38:00    519    19.794513         normal  0.5\n",
      "519 2018-01-31 08:39:00    520    19.193296         normal  0.5\n",
      "520 2018-01-31 08:40:00    521    19.497050         normal  0.5\n",
      "521 2018-01-31 08:41:00    522    20.794197         normal  0.5\n",
      "522 2018-01-31 08:42:00    523    20.896742         normal  0.5\n",
      "523 2018-01-31 08:43:00    524    19.876057         normal  0.5\n",
      "524 2018-01-31 08:44:00    525    20.230949         normal  0.5\n",
      "525 2018-01-31 08:45:00    526    20.784759         normal  0.5\n",
      "526 2018-01-31 08:46:00    527    20.247409         normal  0.5\n",
      "527 2018-01-31 08:47:00    528    22.105122         normal  0.5\n",
      "528 2018-01-31 08:48:00    529    22.199028         normal  0.5\n",
      "529 2018-01-31 08:49:00    530    22.760389         normal  0.5\n",
      "530 2018-01-31 08:50:00    531    22.198277         normal  0.5\n",
      "531 2018-01-31 08:51:00    532    21.890736         normal  0.5\n",
      "532 2018-01-31 08:52:00    533    20.909396         normal  0.5\n",
      "533 2018-01-31 08:53:00    534    22.153773         normal  0.5\n",
      "534 2018-01-31 08:54:00    535    21.809839         normal  0.5\n",
      "535 2018-01-31 08:55:00    536    22.581609         normal  0.5\n",
      "536 2018-01-31 08:56:00    537    22.212988         normal  0.5\n",
      "537 2018-01-31 08:57:00    538    21.795229         normal  0.5\n",
      "538 2018-01-31 08:58:00    539    22.387799         normal  0.5\n",
      "539 2018-01-31 08:59:00    540    22.035208         normal  0.5\n",
      "540 2018-01-31 09:00:00    541    21.651536         normal  0.5\n",
      "541 2018-01-31 09:01:00    542    22.398013         normal  0.5\n",
      "542 2018-01-31 09:02:00    543    21.924276         normal  0.5\n",
      "543 2018-01-31 09:03:00    544    19.897360         normal  0.5\n",
      "544 2018-01-31 09:04:00    545    20.061574         normal  0.5\n",
      "545 2018-01-31 09:05:00    546    20.650542         normal  0.5\n",
      "546 2018-01-31 09:06:00    547    18.765279         normal  0.5\n",
      "547 2018-01-31 09:07:00    548    20.071521         normal  0.5\n",
      "548 2018-01-31 09:08:00    549    19.997574         normal  0.5\n",
      "549 2018-01-31 09:09:00    550    19.684144         normal  0.5\n",
      "550 2018-01-31 09:10:00    551    19.309323         normal  0.5\n",
      "551 2018-01-31 09:11:00    552    18.621292         normal  0.5\n",
      "552 2018-01-31 09:12:00    553    19.406690         normal  0.5\n",
      "553 2018-01-31 09:13:00    554    19.588139         normal  0.5\n",
      "554 2018-01-31 09:14:00    555    19.486517         normal  0.5\n",
      "555 2018-01-31 09:15:00    556    18.922148         normal  0.5\n",
      "556 2018-01-31 09:16:00    557    19.687739         normal  0.5\n",
      "557 2018-01-31 09:17:00    558    20.123397         normal  0.5\n",
      "558 2018-01-31 09:18:00    559    20.793062         normal  0.5\n",
      "559 2018-01-31 09:19:00    560    20.369492         normal  0.5\n",
      "560 2018-01-31 09:20:00    561    19.969789         normal  0.5\n",
      "561 2018-01-31 09:21:00    562    20.581998         normal  0.5\n",
      "562 2018-01-31 09:22:00    563    19.977721         normal  0.5\n",
      "563 2018-01-31 09:23:00    564    20.309407         normal  0.5\n",
      "564 2018-01-31 09:24:00    565    19.712551         normal  0.5\n",
      "565 2018-01-31 09:25:00    566    19.685158         normal  0.5\n",
      "566 2018-01-31 09:26:00    567    18.964581         normal  0.5\n",
      "567 2018-01-31 09:27:00    568    19.629687         normal  0.5\n",
      "568 2018-01-31 09:28:00    569    20.721143         normal  0.5\n",
      "569 2018-01-31 09:29:00    570    19.680279         normal  0.5\n",
      "570 2018-01-31 09:30:00    571    19.654890         normal  0.5\n",
      "571 2018-01-31 09:31:00    572    19.987467         normal  0.5\n",
      "572 2018-01-31 09:32:00    573    19.392027         normal  0.5\n",
      "573 2018-01-31 09:33:00    574    20.407496         normal  0.5\n",
      "574 2018-01-31 09:34:00    575    20.752744         normal  0.5\n",
      "575 2018-01-31 09:35:00    576    19.716406         normal  0.5\n",
      "576 2018-01-31 09:36:00    577    20.357045         normal  0.5\n",
      "577 2018-01-31 09:37:00    578    20.179722         normal  0.5\n",
      "578 2018-01-31 09:38:00    579    20.353044         normal  0.5\n",
      "579 2018-01-31 09:39:00    580    20.330827         normal  0.5\n",
      "580 2018-01-31 09:40:00    581    20.470298         normal  0.5\n",
      "581 2018-01-31 09:41:00    582    20.668976         normal  0.5\n",
      "582 2018-01-31 09:42:00    583    20.370026         normal  0.5\n",
      "583 2018-01-31 09:43:00    584    20.420882         normal  0.5\n",
      "584 2018-01-31 09:44:00    585    19.560569         normal  0.5\n",
      "585 2018-01-31 09:45:00    586    19.501959         normal  0.5\n",
      "586 2018-01-31 09:46:00    587    20.303965         normal  0.5\n",
      "587 2018-01-31 09:47:00    588    19.905109         normal  0.5\n",
      "588 2018-01-31 09:48:00    589    20.858691         normal  0.5\n",
      "589 2018-01-31 09:49:00    590    19.048382         normal  0.5\n",
      "590 2018-01-31 09:50:00    591    19.197520         normal  0.5\n",
      "591 2018-01-31 09:51:00    592    18.845404         normal  0.5\n",
      "592 2018-01-31 09:52:00    593    19.857909         normal  0.5\n",
      "593 2018-01-31 09:53:00    594    20.954386         normal  0.5\n",
      "594 2018-01-31 09:54:00    595    20.110081         normal  0.5\n",
      "595 2018-01-31 09:55:00    596    19.617129         normal  0.5\n",
      "596 2018-01-31 09:56:00    597    20.220342         normal  0.5\n",
      "597 2018-01-31 09:57:00    598    20.447418         normal  0.5\n",
      "598 2018-01-31 09:58:00    599    20.249165         normal  0.5\n",
      "599 2018-01-31 09:59:00    600    19.240046         normal  0.5\n",
      "600 2018-01-31 10:00:00    601    19.819509         normal  0.5\n",
      "601 2018-01-31 10:01:00    602    20.461640         normal  0.5\n",
      "602 2018-01-31 10:02:00    603    20.387482         normal  0.5\n",
      "603 2018-01-31 10:03:00    604    20.214432         normal  0.5\n",
      "604 2018-01-31 10:04:00    605    19.925226         normal  0.5\n",
      "605 2018-01-31 10:05:00    606    19.805747         normal  0.5\n",
      "606 2018-01-31 10:06:00    607    20.235396         normal  0.5\n",
      "607 2018-01-31 10:07:00    608    20.551234         normal  0.5\n",
      "608 2018-01-31 10:08:00    609    20.347508         normal  0.5\n",
      "609 2018-01-31 10:09:00    610    20.924661         normal  0.5\n",
      "610 2018-01-31 10:10:00    611    20.765953         normal  0.5\n",
      "611 2018-01-31 10:11:00    612    20.513604         normal  0.5\n",
      "612 2018-01-31 10:12:00    613    20.627749         normal  0.5\n",
      "613 2018-01-31 10:13:00    614    20.721961         normal  0.5\n",
      "614 2018-01-31 10:14:00    615    19.301742         normal  0.5\n",
      "615 2018-01-31 10:15:00    616    20.291984         normal  0.5\n",
      "616 2018-01-31 10:16:00    617    20.447453         normal  0.5\n",
      "617 2018-01-31 10:17:00    618    20.230411         normal  0.5\n",
      "618 2018-01-31 10:18:00    619    19.568582         normal  0.5\n",
      "619 2018-01-31 10:19:00    620    20.725441         normal  0.5\n",
      "620 2018-01-31 10:20:00    621    20.408421         normal  0.5\n",
      "621 2018-01-31 10:21:00    622    20.541669         normal  0.5\n",
      "622 2018-01-31 10:22:00    623    19.836247         normal  0.5\n",
      "623 2018-01-31 10:23:00    624    18.744361         normal  0.5\n",
      "624 2018-01-31 10:24:00    625    19.767690         normal  0.5\n",
      "625 2018-01-31 10:25:00    626    18.848184         normal  0.5\n",
      "626 2018-01-31 10:26:00    627    17.620475         normal  0.5\n",
      "627 2018-01-31 10:27:00    628    18.698443         normal  0.5\n",
      "628 2018-01-31 10:28:00    629    20.547334         normal  0.5\n",
      "629 2018-01-31 10:29:00    630    19.091464         normal  0.5\n",
      "630 2018-01-31 10:30:00    631    20.264691         normal  0.5\n",
      "631 2018-01-31 10:31:00    632    20.983928         normal  0.5\n",
      "632 2018-01-31 10:32:00    633    20.789979         normal  0.5\n",
      "633 2018-01-31 10:33:00    634    20.479714         normal  0.5\n",
      "634 2018-01-31 10:34:00    635    19.953967         normal  0.5\n",
      "635 2018-01-31 10:35:00    636    18.982157         normal  0.5\n",
      "636 2018-01-31 10:36:00    637    19.601456         normal  0.5\n",
      "637 2018-01-31 10:37:00    638    18.915395         normal  0.5\n",
      "638 2018-01-31 10:38:00    639    19.018920         normal  0.5\n",
      "639 2018-01-31 10:39:00    640    20.262934         normal  0.5\n",
      "640 2018-01-31 10:40:00    641    19.891019         normal  0.5\n",
      "641 2018-01-31 10:41:00    642    19.216402         normal  0.5\n",
      "642 2018-01-31 10:42:00    643    18.552378         normal  0.5\n",
      "643 2018-01-31 10:43:00    644    19.181348         normal  0.5\n",
      "644 2018-01-31 10:44:00    645    19.305819         normal  0.5\n",
      "645 2018-01-31 10:45:00    646    19.084645         normal  0.5\n",
      "646 2018-01-31 10:46:00    647    19.684269         normal  0.5\n",
      "647 2018-01-31 10:47:00    648    19.960497         normal  0.5\n",
      "648 2018-01-31 10:48:00    649    19.963128         normal  0.5\n",
      "649 2018-01-31 10:49:00    650    20.392609         normal  0.5\n",
      "650 2018-01-31 10:50:00    651    19.845819         normal  0.5\n",
      "651 2018-01-31 10:51:00    652    19.191987         normal  0.5\n",
      "652 2018-01-31 10:52:00    653    19.592311         normal  0.5\n",
      "653 2018-01-31 10:53:00    654    20.114532         normal  0.5\n",
      "654 2018-01-31 10:54:00    655    19.606490         normal  0.5\n",
      "655 2018-01-31 10:55:00    656    19.447649         normal  0.5\n",
      "656 2018-01-31 10:56:00    657    20.770870         normal  0.5\n",
      "657 2018-01-31 10:57:00    658    19.457692         normal  0.5\n",
      "658 2018-01-31 10:58:00    659    19.504950         normal  0.5\n",
      "659 2018-01-31 10:59:00    660    20.409452         normal  0.5\n",
      "660 2018-01-31 11:00:00    661    18.924500         normal  0.5\n",
      "661 2018-01-31 11:01:00    662    20.191507         normal  0.5\n",
      "662 2018-01-31 11:02:00    663    18.164767         normal  0.5\n",
      "663 2018-01-31 11:03:00    664    19.509822         normal  0.5\n",
      "664 2018-01-31 11:04:00    665    19.677271         normal  0.5\n",
      "665 2018-01-31 11:05:00    666    19.138541         normal  0.5\n",
      "666 2018-01-31 11:06:00    667    18.947177         normal  0.5\n",
      "667 2018-01-31 11:07:00    668    18.641832         normal  0.5\n",
      "668 2018-01-31 11:08:00    669    18.873607         normal  0.5\n",
      "669 2018-01-31 11:09:00    670    18.606348         normal  0.5\n",
      "670 2018-01-31 11:10:00    671    18.905329         normal  0.5\n",
      "671 2018-01-31 11:11:00    672    19.023751         normal  0.5\n",
      "672 2018-01-31 11:12:00    673    18.216390         normal  0.5\n",
      "673 2018-01-31 11:13:00    674    18.970429         normal  0.5\n",
      "674 2018-01-31 11:14:00    675    18.674780         normal  0.5\n",
      "675 2018-01-31 11:15:00    676    20.253273         normal  0.5\n",
      "676 2018-01-31 11:16:00    677    19.623680         normal  0.5\n",
      "677 2018-01-31 11:17:00    678    20.269519         normal  0.5\n",
      "678 2018-01-31 11:18:00    679    20.167027         normal  0.5\n",
      "679 2018-01-31 11:19:00    680    20.644150         normal  0.5\n",
      "680 2018-01-31 11:20:00    681    19.547965         normal  0.5\n",
      "681 2018-01-31 11:21:00    682    18.256984         normal  0.5\n",
      "682 2018-01-31 11:22:00    683    18.110797         normal  0.5\n",
      "683 2018-01-31 11:23:00    684    18.829628         normal  0.5\n",
      "684 2018-01-31 11:24:00    685    18.301410         normal  0.5\n",
      "685 2018-01-31 11:25:00    686    18.552905         normal  0.5\n",
      "686 2018-01-31 11:26:00    687    20.492111         normal  0.5\n",
      "687 2018-01-31 11:27:00    688    20.170672         normal  0.5\n",
      "688 2018-01-31 11:28:00    689    19.792877         normal  0.5\n",
      "689 2018-01-31 11:29:00    690    19.705552         normal  0.5\n",
      "690 2018-01-31 11:30:00    691    19.596047         normal  0.5\n",
      "691 2018-01-31 11:31:00    692    20.465621         normal  0.5\n",
      "692 2018-01-31 11:32:00    693    20.271564         normal  0.5\n",
      "693 2018-01-31 11:33:00    694    19.279639         normal  0.5\n",
      "694 2018-01-31 11:34:00    695    20.109325         normal  0.5\n",
      "695 2018-01-31 11:35:00    696    20.941383         normal  0.5\n",
      "696 2018-01-31 11:36:00    697    19.680818         normal  0.5\n",
      "697 2018-01-31 11:37:00    698    20.871219         normal  0.5\n",
      "698 2018-01-31 11:38:00    699    19.327586         normal  0.5\n",
      "699 2018-01-31 11:39:00    700    20.808008         normal  0.5\n",
      "700 2018-01-31 11:40:00    701    20.535492         normal  0.5\n",
      "701 2018-01-31 11:41:00    702    20.611392         normal  0.5\n",
      "702 2018-01-31 11:42:00    703    20.008142         normal  0.5\n",
      "703 2018-01-31 11:43:00    704    19.920903         normal  0.5\n",
      "704 2018-01-31 11:44:00    705    20.299626         normal  0.5\n",
      "705 2018-01-31 11:45:00    706    20.007698         normal  0.5\n",
      "706 2018-01-31 11:46:00    707    20.249605         normal  0.5\n",
      "707 2018-01-31 11:47:00    708    20.149994         normal  0.5\n",
      "708 2018-01-31 11:48:00    709    19.944827         normal  0.5\n",
      "709 2018-01-31 11:49:00    710    20.149673         normal  0.5\n",
      "710 2018-01-31 11:50:00    711    19.590707         normal  0.5\n",
      "711 2018-01-31 11:51:00    712    19.497938         normal  0.5\n",
      "712 2018-01-31 11:52:00    713    19.593712         normal  0.5\n",
      "713 2018-01-31 11:53:00    714    19.657390         normal  0.5\n",
      "714 2018-01-31 11:54:00    715    20.847762         normal  0.5\n",
      "715 2018-01-31 11:55:00    716    20.221767         normal  0.5\n",
      "716 2018-01-31 11:56:00    717    19.600081         normal  0.5\n",
      "717 2018-01-31 11:57:00    718    20.280131         normal  0.5\n",
      "718 2018-01-31 11:58:00    719    19.332353         normal  0.5\n",
      "719 2018-01-31 11:59:00    720    20.886997         normal  0.5\n",
      "720 2018-01-31 12:00:00    721    19.691094         normal  0.5\n",
      "721 2018-01-31 12:01:00    722    20.339914         normal  0.5\n",
      "722 2018-01-31 12:02:00    723    19.644146         normal  0.5\n",
      "723 2018-01-31 12:03:00    724    20.098498         normal  0.5\n",
      "724 2018-01-31 12:04:00    725    19.576740         normal  0.5\n",
      "725 2018-01-31 12:05:00    726    20.681836         normal  0.5\n",
      "726 2018-01-31 12:06:00    727    18.941668         normal  0.5\n",
      "727 2018-01-31 12:07:00    728    19.419225         normal  0.5\n",
      "728 2018-01-31 12:08:00    729    19.475886         normal  0.5\n",
      "729 2018-01-31 12:09:00    730    20.444654         normal  0.5\n",
      "730 2018-01-31 12:10:00    731    20.753334         normal  0.5\n",
      "731 2018-01-31 12:11:00    732    20.447104         normal  0.5\n",
      "732 2018-01-31 12:12:00    733    20.503710         normal  0.5\n",
      "733 2018-01-31 12:13:00    734    20.269972         normal  0.5\n",
      "734 2018-01-31 12:14:00    735    20.293275         normal  0.5\n",
      "735 2018-01-31 12:15:00    736    21.079421         normal  0.5\n",
      "736 2018-01-31 12:16:00    737    20.552252         normal  0.5\n",
      "737 2018-01-31 12:17:00    738    20.709410         normal  0.5\n",
      "738 2018-01-31 12:18:00    739    20.031837         normal  0.5\n",
      "739 2018-01-31 12:19:00    740    19.615606         normal  0.5\n",
      "740 2018-01-31 12:20:00    741    19.793937         normal  0.5\n",
      "741 2018-01-31 12:21:00    742    20.325857         normal  0.5\n",
      "742 2018-01-31 12:22:00    743    20.351321         normal  0.5\n",
      "743 2018-01-31 12:23:00    744    19.607733         normal  0.5\n",
      "744 2018-01-31 12:24:00    745    19.995081         normal  0.5\n",
      "745 2018-01-31 12:25:00    746    19.576047         normal  0.5\n",
      "746 2018-01-31 12:26:00    747    20.723366         normal  0.5\n",
      "747 2018-01-31 12:27:00    748    20.129466         normal  0.5\n",
      "748 2018-01-31 12:28:00    749    20.568331         normal  0.5\n",
      "749 2018-01-31 12:29:00    750    19.373409         normal  0.5\n",
      "750 2018-01-31 12:30:00    751    20.236155         normal  0.5\n",
      "751 2018-01-31 12:31:00    752    21.136496         normal  0.5\n",
      "752 2018-01-31 12:32:00    753    20.693284         normal  0.5\n",
      "753 2018-01-31 12:33:00    754    20.928078         normal  0.5\n",
      "754 2018-01-31 12:34:00    755    19.249643         normal  0.5\n",
      "755 2018-01-31 12:35:00    756    19.659865         normal  0.5\n",
      "756 2018-01-31 12:36:00    757    20.349136         normal  0.5\n",
      "757 2018-01-31 12:37:00    758    20.416038         normal  0.5\n",
      "758 2018-01-31 12:38:00    759    19.757306         normal  0.5\n",
      "759 2018-01-31 12:39:00    760    20.176729         normal  0.5\n",
      "760 2018-01-31 12:40:00    761    21.139040         normal  0.5\n",
      "761 2018-01-31 12:41:00    762    20.850320         normal  0.5\n",
      "762 2018-01-31 12:42:00    763    20.629720         normal  0.5\n",
      "763 2018-01-31 12:43:00    764    19.933260         normal  0.5\n",
      "764 2018-01-31 12:44:00    765    19.762840         normal  0.5\n",
      "765 2018-01-31 12:45:00    766    20.040021         normal  0.5\n",
      "766 2018-01-31 12:46:00    767    19.574620         normal  0.5\n",
      "767 2018-01-31 12:47:00    768    19.799087         normal  0.5\n",
      "768 2018-01-31 12:48:00    769    20.240789         normal  0.5\n",
      "769 2018-01-31 12:49:00    770    20.990125         normal  0.5\n",
      "770 2018-01-31 12:50:00    771    21.168783         normal  0.5\n",
      "771 2018-01-31 12:51:00    772    20.226629         normal  0.5\n",
      "772 2018-01-31 12:52:00    773    20.939320         normal  0.5\n",
      "773 2018-01-31 12:53:00    774    21.613109         normal  0.5\n",
      "774 2018-01-31 12:54:00    775    21.225974         normal  0.5\n",
      "775 2018-01-31 12:55:00    776    20.442562         normal  0.5\n",
      "776 2018-01-31 12:56:00    777    20.651274         normal  0.5\n",
      "777 2018-01-31 12:57:00    778    20.678753         normal  0.5\n",
      "778 2018-01-31 12:58:00    779    21.031650         normal  0.5\n",
      "779 2018-01-31 12:59:00    780    20.204068         normal  0.5\n",
      "780 2018-01-31 13:00:00    781    19.801835         normal  0.5\n",
      "781 2018-01-31 13:01:00    782    20.966286         normal  0.5\n",
      "782 2018-01-31 13:02:00    783    21.101060         normal  0.5\n",
      "783 2018-01-31 13:03:00    784    19.306707         normal  0.5\n",
      "784 2018-01-31 13:04:00    785    20.436246         normal  0.5\n",
      "785 2018-01-31 13:05:00    786    20.762063         normal  0.5\n",
      "786 2018-01-31 13:06:00    787    20.557400         normal  0.5\n",
      "787 2018-01-31 13:07:00    788    20.563493         normal  0.5\n",
      "788 2018-01-31 13:08:00    789    20.052232         normal  0.5\n",
      "789 2018-01-31 13:09:00    790    19.694673         normal  0.5\n",
      "790 2018-01-31 13:10:00    791    20.041418         normal  0.5\n",
      "791 2018-01-31 13:11:00    792    19.520040         normal  0.5\n",
      "792 2018-01-31 13:12:00    793    20.478587         normal  0.5\n",
      "793 2018-01-31 13:13:00    794    20.452443         normal  0.5\n",
      "794 2018-01-31 13:14:00    795    18.791598         normal  0.5\n",
      "795 2018-01-31 13:15:00    796    19.690517         normal  0.5\n",
      "796 2018-01-31 13:16:00    797    19.335639         normal  0.5\n",
      "797 2018-01-31 13:17:00    798    20.069047         normal  0.5\n",
      "798 2018-01-31 13:18:00    799    21.752647         normal  0.5\n",
      "799 2018-01-31 13:19:00    800    20.505741         normal  0.5\n",
      "800 2018-01-31 13:20:00    801    19.764692         normal  0.5\n",
      "801 2018-01-31 13:21:00    802    19.900315         normal  0.5\n",
      "802 2018-01-31 13:22:00    803    20.045768         normal  0.5\n",
      "803 2018-01-31 13:23:00    804    20.760398         normal  0.5\n",
      "804 2018-01-31 13:24:00    805    20.269477         normal  0.5\n",
      "805 2018-01-31 13:25:00    806    19.703526         normal  0.5\n",
      "806 2018-01-31 13:26:00    807    19.581562         normal  0.5\n",
      "807 2018-01-31 13:27:00    808    21.201638         normal  0.5\n",
      "808 2018-01-31 13:28:00    809    19.977703         normal  0.5\n",
      "809 2018-01-31 13:29:00    810    20.184160  abnormal(hot)  0.5\n",
      "810 2018-01-31 13:30:00    811    20.135766  abnormal(hot)  0.5\n",
      "811 2018-01-31 13:31:00    812    20.091647  abnormal(hot)  0.5\n",
      "812 2018-01-31 13:32:00    813    20.596067  abnormal(hot)  0.5\n",
      "813 2018-01-31 13:33:00    814    20.121229  abnormal(hot)  0.5\n",
      "814 2018-01-31 13:34:00    815    20.238723  abnormal(hot)  0.5\n",
      "815 2018-01-31 13:35:00    816    22.262348  abnormal(hot)  0.5\n",
      "816 2018-01-31 13:36:00    817    19.788647  abnormal(hot)  0.5\n",
      "817 2018-01-31 13:37:00    818    19.888048  abnormal(hot)  0.5\n",
      "818 2018-01-31 13:38:00    819    19.841865  abnormal(hot)  0.5\n",
      "819 2018-01-31 13:39:00    820    19.827943  abnormal(hot)  0.5\n",
      "820 2018-01-31 13:40:00    821    20.066358  abnormal(hot)  0.5\n",
      "821 2018-01-31 13:41:00    822    19.425517  abnormal(hot)  0.5\n",
      "822 2018-01-31 13:42:00    823    19.083865  abnormal(hot)  0.5\n",
      "823 2018-01-31 13:43:00    824    19.873859  abnormal(hot)  0.5\n",
      "824 2018-01-31 13:44:00    825    18.455811  abnormal(hot)  0.5\n",
      "825 2018-01-31 13:45:00    826    19.108488  abnormal(hot)  0.5\n",
      "826 2018-01-31 13:46:00    827    19.569318  abnormal(hot)  0.5\n",
      "827 2018-01-31 13:47:00    828    19.596161  abnormal(hot)  0.5\n",
      "828 2018-01-31 13:48:00    829    20.525878  abnormal(hot)  0.5\n",
      "829 2018-01-31 13:49:00    830    19.555039  abnormal(hot)  0.5\n",
      "830 2018-01-31 13:50:00    831    19.627301  abnormal(hot)  0.5\n",
      "831 2018-01-31 13:51:00    832    19.750897  abnormal(hot)  0.5\n",
      "832 2018-01-31 13:52:00    833    19.958682  abnormal(hot)  0.5\n",
      "833 2018-01-31 13:53:00    834    19.999529  abnormal(hot)  0.5\n",
      "834 2018-01-31 13:54:00    835    19.193929  abnormal(hot)  0.5\n",
      "835 2018-01-31 13:55:00    836    20.551374  abnormal(hot)  0.5\n",
      "836 2018-01-31 13:56:00    837    19.452082  abnormal(hot)  0.5\n",
      "837 2018-01-31 13:57:00    838    19.229453  abnormal(hot)  0.5\n",
      "838 2018-01-31 13:58:00    839    18.041236  abnormal(hot)  0.5\n",
      "839 2018-01-31 13:59:00    840    18.511035  abnormal(hot)  0.5\n",
      "840 2018-01-31 14:00:00    841    18.269660  abnormal(hot)  0.5\n",
      "841 2018-01-31 14:01:00    842    17.848889  abnormal(hot)  0.5\n",
      "842 2018-01-31 14:02:00    843    19.355484  abnormal(hot)  0.5\n",
      "843 2018-01-31 14:03:00    844    19.401956  abnormal(hot)  0.5\n",
      "844 2018-01-31 14:04:00    845    18.958139  abnormal(hot)  0.5\n",
      "845 2018-01-31 14:05:00    846    19.671955  abnormal(hot)  0.5\n",
      "846 2018-01-31 14:06:00    847    19.713108  abnormal(hot)  0.5\n",
      "847 2018-01-31 14:07:00    848    19.062842  abnormal(hot)  0.5\n",
      "848 2018-01-31 14:08:00    849    20.800845  abnormal(hot)  0.5\n",
      "849 2018-01-31 14:09:00    850    20.001970  abnormal(hot)  0.5\n",
      "850 2018-01-31 14:10:00    851    20.684771  abnormal(hot)  0.5\n",
      "851 2018-01-31 14:11:00    852    20.482369  abnormal(hot)  0.5\n",
      "852 2018-01-31 14:12:00    853    19.764717  abnormal(hot)  0.5\n",
      "853 2018-01-31 14:13:00    854    20.293052  abnormal(hot)  0.5\n",
      "854 2018-01-31 14:14:00    855    20.537143  abnormal(hot)  0.5\n",
      "855 2018-01-31 14:15:00    856    20.137548  abnormal(hot)  0.5\n",
      "856 2018-01-31 14:16:00    857    21.342653  abnormal(hot)  0.5\n",
      "857 2018-01-31 14:17:00    858    20.680007  abnormal(hot)  0.5\n",
      "858 2018-01-31 14:18:00    859    19.651637  abnormal(hot)  0.5\n",
      "859 2018-01-31 14:19:00    860    18.407661  abnormal(hot)  0.5\n",
      "860 2018-01-31 14:20:00    861    19.408713  abnormal(hot)  0.5\n",
      "861 2018-01-31 14:21:00    862    19.568703  abnormal(hot)  0.5\n",
      "862 2018-01-31 14:22:00    863    19.127708  abnormal(hot)  0.5\n",
      "863 2018-01-31 14:23:00    864    19.174382  abnormal(hot)  0.5\n",
      "864 2018-01-31 14:24:00    865    19.762245  abnormal(hot)  0.5\n",
      "865 2018-01-31 14:25:00    866    19.959564  abnormal(hot)  0.5\n",
      "866 2018-01-31 14:26:00    867    20.064898  abnormal(hot)  0.5\n",
      "867 2018-01-31 14:27:00    868    19.421413  abnormal(hot)  0.5\n",
      "868 2018-01-31 14:28:00    869    23.253021  abnormal(hot)  0.5\n",
      "869 2018-01-31 14:29:00    870    20.082702         normal  0.5\n",
      "870 2018-01-31 14:30:00    871    20.039162         normal  0.5\n",
      "871 2018-01-31 14:31:00    872    20.690262         normal  0.5\n",
      "872 2018-01-31 14:32:00    873    20.387725         normal  0.5\n",
      "873 2018-01-31 14:33:00    874    20.754515         normal  0.5\n",
      "874 2018-01-31 14:34:00    875    21.636769         normal  0.5\n",
      "875 2018-01-31 14:35:00    876    21.236228         normal  0.5\n",
      "876 2018-01-31 14:36:00    877    21.210230         normal  0.5\n",
      "877 2018-01-31 14:37:00    878    21.587911         normal  0.5\n",
      "878 2018-01-31 14:38:00    879    21.559511         normal  0.5\n",
      "879 2018-01-31 14:39:00    880    21.022647         normal  0.5\n",
      "880 2018-01-31 14:40:00    881    19.740509         normal  0.5\n",
      "881 2018-01-31 14:41:00    882    20.437647         normal  0.5\n",
      "882 2018-01-31 14:42:00    883    19.170492         normal  0.5\n",
      "883 2018-01-31 14:43:00    884    19.318663         normal  0.5\n",
      "884 2018-01-31 14:44:00    885    20.546277         normal  0.5\n",
      "885 2018-01-31 14:45:00    886    22.215379         normal  0.5\n",
      "886 2018-01-31 14:46:00    887    19.592374         normal  0.5\n",
      "887 2018-01-31 14:47:00    888    20.306287         normal  0.5\n",
      "888 2018-01-31 14:48:00    889    20.477238         normal  0.5\n",
      "889 2018-01-31 14:49:00    890    20.103550         normal  0.5\n",
      "890 2018-01-31 14:50:00    891    20.156335         normal  0.5\n",
      "891 2018-01-31 14:51:00    892    19.837876         normal  0.5\n",
      "892 2018-01-31 14:52:00    893    20.329398         normal  0.5\n",
      "893 2018-01-31 14:53:00    894    20.367110         normal  0.5\n",
      "894 2018-01-31 14:54:00    895    21.004429         normal  0.5\n",
      "895 2018-01-31 14:55:00    896    20.570546         normal  0.5\n",
      "896 2018-01-31 14:56:00    897    20.417811         normal  0.5\n",
      "897 2018-01-31 14:57:00    898    21.312516         normal  0.5\n",
      "898 2018-01-31 14:58:00    899    20.811370         normal  0.5\n",
      "899 2018-01-31 14:59:00    900    20.523358         normal  0.5\n",
      "900 2018-01-31 15:00:00    901    20.147202         normal  0.5\n",
      "901 2018-01-31 15:01:00    902    19.241089         normal  0.5\n",
      "902 2018-01-31 15:02:00    903    20.286745         normal  0.5\n",
      "903 2018-01-31 15:03:00    904    19.882722         normal  0.5\n",
      "904 2018-01-31 15:04:00    905    19.835789         normal  0.5\n",
      "905 2018-01-31 15:05:00    906    19.380964         normal  0.5\n",
      "906 2018-01-31 15:06:00    907    20.493220         normal  0.5\n",
      "907 2018-01-31 15:07:00    908    20.919345         normal  0.5\n",
      "908 2018-01-31 15:08:00    909    20.064562         normal  0.5\n",
      "909 2018-01-31 15:09:00    910    21.002400         normal  0.5\n",
      "910 2018-01-31 15:10:00    911    21.768425         normal  0.5\n",
      "911 2018-01-31 15:11:00    912    20.866024         normal  0.5\n",
      "912 2018-01-31 15:12:00    913    21.175353         normal  0.5\n",
      "913 2018-01-31 15:13:00    914    19.817778         normal  0.5\n",
      "914 2018-01-31 15:14:00    915    19.264010         normal  0.5\n",
      "915 2018-01-31 15:15:00    916    19.258120         normal  0.5\n",
      "916 2018-01-31 15:16:00    917    19.469858         normal  0.5\n",
      "917 2018-01-31 15:17:00    918    20.024392         normal  0.5\n",
      "918 2018-01-31 15:18:00    919    19.832450         normal  0.5\n",
      "919 2018-01-31 15:19:00    920    20.514120         normal  0.5\n",
      "920 2018-01-31 15:20:00    921    20.079753         normal  0.5\n",
      "921 2018-01-31 15:21:00    922    18.798361         normal  0.5\n",
      "922 2018-01-31 15:22:00    923    19.649489         normal  0.5\n",
      "923 2018-01-31 15:23:00    924    19.294546         normal  0.5\n",
      "924 2018-01-31 15:24:00    925    19.766536         normal  0.5\n",
      "925 2018-01-31 15:25:00    926    19.963034         normal  0.5\n",
      "926 2018-01-31 15:26:00    927    20.604646         normal  0.5\n",
      "927 2018-01-31 15:27:00    928    19.627324         normal  0.5\n",
      "928 2018-01-31 15:28:00    929    19.645227         normal  0.5\n",
      "929 2018-01-31 15:29:00    930    19.745202         normal  0.5\n",
      "930 2018-01-31 15:30:00    931    20.134360         normal  0.5\n",
      "931 2018-01-31 15:31:00    932    20.167910         normal  0.5\n",
      "932 2018-01-31 15:32:00    933    19.658160         normal  0.5\n",
      "933 2018-01-31 15:33:00    934    20.191979         normal  0.5\n",
      "934 2018-01-31 15:34:00    935    19.351315         normal  0.5\n",
      "935 2018-01-31 15:35:00    936    19.761344         normal  0.5\n",
      "936 2018-01-31 15:36:00    937    19.224941         normal  0.5\n",
      "937 2018-01-31 15:37:00    938    19.374490         normal  0.5\n",
      "938 2018-01-31 15:38:00    939    19.833088         normal  0.5\n",
      "939 2018-01-31 15:39:00    940    20.339912         normal  0.5\n",
      "940 2018-01-31 15:40:00    941    19.804947         normal  0.5\n",
      "941 2018-01-31 15:41:00    942    20.292255         normal  0.5\n",
      "942 2018-01-31 15:42:00    943    19.692242         normal  0.5\n",
      "943 2018-01-31 15:43:00    944    19.637457         normal  0.5\n",
      "944 2018-01-31 15:44:00    945    19.847224         normal  0.5\n",
      "945 2018-01-31 15:45:00    946    20.113901         normal  0.5\n",
      "946 2018-01-31 15:46:00    947    19.739296         normal  0.5\n",
      "947 2018-01-31 15:47:00    948    19.898178         normal  0.5\n",
      "948 2018-01-31 15:48:00    949    19.486738         normal  0.5\n",
      "949 2018-01-31 15:49:00    950    21.006580         normal  0.5\n",
      "950 2018-01-31 15:50:00    951    20.270173         normal  0.5\n",
      "951 2018-01-31 15:51:00    952    20.517797         normal  0.5\n",
      "952 2018-01-31 15:52:00    953    20.163804         normal  0.5\n",
      "953 2018-01-31 15:53:00    954    20.407918         normal  0.5\n",
      "954 2018-01-31 15:54:00    955    20.531247         normal  0.5\n",
      "955 2018-01-31 15:55:00    956    19.913767         normal  0.5\n",
      "956 2018-01-31 15:56:00    957    20.222553         normal  0.5\n",
      "957 2018-01-31 15:57:00    958    19.289177         normal  0.5\n",
      "958 2018-01-31 15:58:00    959    19.974267         normal  0.5\n",
      "959 2018-01-31 15:59:00    960    19.346319         normal  0.5\n",
      "960 2018-01-31 16:00:00    961    20.313464         normal  0.5\n",
      "961 2018-01-31 16:01:00    962    19.366142         normal  0.5\n",
      "962 2018-01-31 16:02:00    963    19.048104         normal  0.5\n",
      "963 2018-01-31 16:03:00    964    19.471823         normal  0.5\n",
      "964 2018-01-31 16:04:00    965    19.282604         normal  0.5\n",
      "965 2018-01-31 16:05:00    966    18.458655         normal  0.5\n",
      "966 2018-01-31 16:06:00    967    19.120520         normal  0.5\n",
      "967 2018-01-31 16:07:00    968    19.261035         normal  0.5\n",
      "968 2018-01-31 16:08:00    969    18.819051         normal  0.5\n",
      "969 2018-01-31 16:09:00    970    18.945195         normal  0.5\n",
      "970 2018-01-31 16:10:00    971    19.578329         normal  0.5\n",
      "971 2018-01-31 16:11:00    972    19.314626         normal  0.5\n",
      "972 2018-01-31 16:12:00    973    19.512977         normal  0.5\n",
      "973 2018-01-31 16:13:00    974    20.345359         normal  0.5\n",
      "974 2018-01-31 16:14:00    975    20.241458         normal  0.5\n",
      "975 2018-01-31 16:15:00    976    19.746776         normal  0.5\n",
      "976 2018-01-31 16:16:00    977    19.818673         normal  0.5\n",
      "977 2018-01-31 16:17:00    978    19.269812         normal  0.5\n",
      "978 2018-01-31 16:18:00    979    21.088775         normal  0.5\n",
      "979 2018-01-31 16:19:00    980    19.968935         normal  0.5\n",
      "980 2018-01-31 16:20:00    981    19.392172         normal  0.5\n",
      "981 2018-01-31 16:21:00    982    19.439726         normal  0.5\n",
      "982 2018-01-31 16:22:00    983    20.642755         normal  0.5\n",
      "983 2018-01-31 16:23:00    984    20.432261         normal  0.5\n",
      "984 2018-01-31 16:24:00    985    19.359982         normal  0.5\n",
      "985 2018-01-31 16:25:00    986    18.786020         normal  0.5\n",
      "986 2018-01-31 16:26:00    987    19.170037         normal  0.5\n",
      "987 2018-01-31 16:27:00    988    18.671712         normal  0.5\n",
      "988 2018-01-31 16:28:00    989    20.966998         normal  0.5\n",
      "989 2018-01-31 16:29:00    990    19.668637         normal  0.5\n",
      "990 2018-01-31 16:30:00    991    19.853393         normal  0.5\n",
      "991 2018-01-31 16:31:00    992    20.315523         normal  0.5\n",
      "992 2018-01-31 16:32:00    993    20.292629         normal  0.5\n",
      "993 2018-01-31 16:33:00    994    19.849037         normal  0.5\n",
      "994 2018-01-31 16:34:00    995    20.366645         normal  0.5\n",
      "995 2018-01-31 16:35:00    996    21.600618         normal  0.5\n",
      "996 2018-01-31 16:36:00    997    21.507423         normal  0.5\n",
      "997 2018-01-31 16:37:00    998    20.757795         normal  0.5\n",
      "998 2018-01-31 16:38:00    999    20.467804         normal  0.5\n",
      "999 2018-01-31 16:39:00   1000    20.898813         normal  0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file saved\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TRAIN, data preparation\n",
    "-RUL is not applicable in this case, \n",
    "because the dataset not results from R2F simulation or experiemtns\n",
    "'''\n",
    "#Data labeling: the label indicates state 1hour before occuring state change\n",
    "\n",
    "## Label construction\n",
    "# labeled_features = final_feat.merge(failures, on=['datetime', 'machineID'], how='left')\n",
    "\n",
    "# 1hr time delta resampling with min,max \n",
    "# Create indicator array ( min<17:cold, max>23:hot)\n",
    "label_arr = np.zeros(len(df_Temp), dtype = object)\n",
    "# label_arr = np.empty(len(max_60_arr))\n",
    "# label_arr[:] = np.nan\n",
    "print (\"label_arr\", label_arr)\n",
    "\n",
    "tmp_arr = df_Temp['temperature']\n",
    "\n",
    "label_arr[((tmp_arr>=17) & (tmp_arr<=23)) ] = 'normal'\n",
    "label_arr[tmp_arr<17] = 'abnormal(cold)'\n",
    "label_arr[tmp_arr>23] ='abnormal(hot)'\n",
    "\n",
    "print (\"label_arr\", label_arr)\n",
    "print (np.sum([label_arr == 'normal']))\n",
    "print (np.sum([label_arr == 'abnormal(cold)']))\n",
    "print (np.sum([label_arr == 'abnormal(hot)']))\n",
    "\n",
    "df_Temp['label'] = label_arr\n",
    "\n",
    "df_Temp_cp = df_Temp.copy()\n",
    "\n",
    "\n",
    "# Concatenate to feature frame\n",
    "# Convert 'normal'state as 'NaN' (same as missing data aligned to date)\n",
    "df_Temp_cp.loc[df_Temp['label'] == 'normal','label'] = np.nan\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "# Fill N/A with bfill limit 5 (fill backward up to 1hr (60mins))\n",
    "df_Temp_cp['label'] = df_Temp_cp['label'].fillna(method='bfill', limit=59)\n",
    "print(\"bfill abnormal state...\")\n",
    "# Otherwise(normal operation) should be 'none'\n",
    "df_Temp_cp['label'] = df_Temp_cp['label'].fillna('normal')\n",
    "print(\"fill in residual normal state...\")\n",
    "# print (\"labeled_temp_feat\", labeled_temp_feat)\n",
    "# print (\"labeled_temp_feat.head(500)\", labeled_temp_feat.head(500))\n",
    "\n",
    "df_Temp_cp = df_Temp_cp[['date','cycle', 'temperature', 'label']]\n",
    "df_Temp_cp['pad'] = np.ones(len(df_Temp))/2\n",
    "df_Temp_cp\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "print (df_Temp_cp.head(1000))\n",
    "# print (labeled_temp_feat[['min_temp_10_min','max_temp_10_min','date','label']].head(1000))\n",
    "\n",
    "df_Temp_cp.to_csv('labeled_temp_LSTM.csv', index=False)\n",
    "print (\"csv file saved\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_Temp_cp['date'][0] 2018-01-31 00:00:00\n",
      "last_train_date 2020-02-05 11:00:00\n",
      "1059060\n",
      "1059060\n",
      "78540\n",
      "78540\n",
      "                       date  pad  label_abnormal(cold)  label_abnormal(hot)  \\\n",
      "0       2018-01-31 00:00:00  0.5                     0                    1   \n",
      "1       2018-01-31 00:01:00  0.5                     0                    1   \n",
      "2       2018-01-31 00:02:00  0.5                     0                    1   \n",
      "3       2018-01-31 00:03:00  0.5                     0                    1   \n",
      "4       2018-01-31 00:04:00  0.5                     0                    1   \n",
      "...                     ...  ...                   ...                  ...   \n",
      "1059055 2020-02-05 10:55:00  0.5                     0                    0   \n",
      "1059056 2020-02-05 10:56:00  0.5                     0                    0   \n",
      "1059057 2020-02-05 10:57:00  0.5                     0                    0   \n",
      "1059058 2020-02-05 10:58:00  0.5                     0                    0   \n",
      "1059059 2020-02-05 10:59:00  0.5                     0                    0   \n",
      "\n",
      "         label_normal      label_str  \n",
      "0                   0  abnormal(hot)  \n",
      "1                   0  abnormal(hot)  \n",
      "2                   0  abnormal(hot)  \n",
      "3                   0  abnormal(hot)  \n",
      "4                   0  abnormal(hot)  \n",
      "...               ...            ...  \n",
      "1059055             1         normal  \n",
      "1059056             1         normal  \n",
      "1059057             1         normal  \n",
      "1059058             1         normal  \n",
      "1059059             1         normal  \n",
      "\n",
      "[1059060 rows x 6 columns]\n",
      "                       date  pad  label_abnormal(cold)  label_abnormal(hot)  \\\n",
      "1059061 2020-02-05 11:01:00  0.5                     0                    0   \n",
      "1059062 2020-02-05 11:02:00  0.5                     0                    0   \n",
      "1059063 2020-02-05 11:03:00  0.5                     0                    0   \n",
      "1059064 2020-02-05 11:04:00  0.5                     0                    0   \n",
      "1059065 2020-02-05 11:05:00  0.5                     0                    0   \n",
      "...                     ...  ...                   ...                  ...   \n",
      "1137596 2020-03-30 23:56:00  0.5                     0                    0   \n",
      "1137597 2020-03-30 23:57:00  0.5                     0                    0   \n",
      "1137598 2020-03-30 23:58:00  0.5                     0                    0   \n",
      "1137599 2020-03-30 23:59:00  0.5                     0                    0   \n",
      "1137600 2020-03-31 00:00:00  0.5                     0                    0   \n",
      "\n",
      "         label_normal label_str  \n",
      "1059061             1    normal  \n",
      "1059062             1    normal  \n",
      "1059063             1    normal  \n",
      "1059064             1    normal  \n",
      "1059065             1    normal  \n",
      "...               ...       ...  \n",
      "1137596             1    normal  \n",
      "1137597             1    normal  \n",
      "1137598             1    normal  \n",
      "1137599             1    normal  \n",
      "1137600             1    normal  \n",
      "\n",
      "[78540 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Split dataset into Training/Test sets\n",
    "'''\n",
    "\n",
    "## Function to derive current time with the format of pandas timestamp '%Y-%m-%d %H:%M:00' \n",
    "def current_time():\n",
    "    ct = datetime.now()\n",
    "    ct_minute = ct.strftime('%Y-%m-%d %H:00:00')\n",
    "#     ct_ts = pd.to_datetime(ct_minute)\n",
    "    ct_ts = pd.Timestamp(ct_minute, freq='t')\n",
    "    return ct_ts\n",
    "\n",
    "## Generate a fixed frequency DatetimeIndex\n",
    "# Set current time(minute) as the threshold for training/test dataset split \n",
    "current_minute = current_time()\n",
    "\n",
    "print (\"df_Temp_cp['date'][0]\", df_Temp_cp['date'][0] )\n",
    "\n",
    "# threshold_dates = [[df_Temp_cp['date'][0],current_minute ],\n",
    "#                    [current_minute, df_Temp_cp['date'].iloc[-1]]]\n",
    "\n",
    "# for last_train_date, first_test_date in threshold_dates:\n",
    "#     print (\"last_train_date\", last_train_date)\n",
    "#     print(\"first_test_date\", first_test_date)\n",
    "\n",
    "\n",
    "# print (\"current_minute\", current_minute)\n",
    "# print (\"Total number of instances\", len(df_Temp_cp['date']))\n",
    "# print (\"The number of training instances\", np.where(df_Temp_cp['date']==current_minute)[0][0]+1)\n",
    "# print (\"The number of test instances\", len(df_Temp_cp['date']) - (np.where(df_Temp_cp['date']==current_minute)[0][0]+1) )\n",
    "\n",
    "\n",
    "# make test and training splits\n",
    "test_results = []\n",
    "models = []\n",
    "last_train_date = current_minute\n",
    "first_test_date  = current_minute\n",
    "print (\"last_train_date\", last_train_date)\n",
    "# split out training and test data\n",
    "# train_y_df = df_Temp_cp.loc[df_Temp_cp['date'] < last_train_date, 'label']\n",
    "## Generate multi classes for softmax multiclass classification\n",
    "train_y_df = pd.get_dummies(df_Temp_cp.loc[df_Temp_cp['date']  < last_train_date].drop(['cycle','temperature'], 1))\n",
    "\n",
    "train_x_df = pd.get_dummies(df_Temp_cp.loc[df_Temp_cp['date']  < last_train_date].drop(['date','cycle','label'], 1))\n",
    "\n",
    "test_x_df = pd.get_dummies(df_Temp_cp.loc[df_Temp_cp['date'] > first_test_date].drop(['date','cycle','label'], 1))\n",
    "\n",
    "test_truth_df = pd.get_dummies(df_Temp_cp.loc[df_Temp_cp['date'] > first_test_date].drop(['cycle','temperature'], 1))\n",
    "\n",
    "\n",
    "train_y_df['label_str'] = df_Temp_cp.loc[df_Temp_cp['date'] < last_train_date, 'label']\n",
    "test_truth_df['label_str'] = df_Temp_cp.loc[df_Temp_cp['date'] > first_test_date, 'label']\n",
    "\n",
    "print (len(train_x_df))\n",
    "print (len(train_y_df))\n",
    "print (len(test_x_df))\n",
    "print (len(test_truth_df))\n",
    "\n",
    "\n",
    "print (train_y_df)\n",
    "print (test_truth_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1058880, 180, 2)\n",
      "[[[0.4606461  0.5       ]\n",
      "  [0.38246593 0.5       ]\n",
      "  [0.4833669  0.5       ]\n",
      "  ...\n",
      "  [0.42887783 0.5       ]\n",
      "  [0.5146476  0.5       ]\n",
      "  [0.5554207  0.5       ]]\n",
      "\n",
      " [[0.38246593 0.5       ]\n",
      "  [0.4833669  0.5       ]\n",
      "  [0.5169582  0.5       ]\n",
      "  ...\n",
      "  [0.5146476  0.5       ]\n",
      "  [0.5554207  0.5       ]\n",
      "  [0.5181797  0.5       ]]\n",
      "\n",
      " [[0.4833669  0.5       ]\n",
      "  [0.5169582  0.5       ]\n",
      "  [0.34696934 0.5       ]\n",
      "  ...\n",
      "  [0.5554207  0.5       ]\n",
      "  [0.5181797  0.5       ]\n",
      "  [0.57424533 0.5       ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.4578503  0.5       ]\n",
      "  [0.5112358  0.5       ]\n",
      "  [0.52274656 0.5       ]\n",
      "  ...\n",
      "  [0.3035485  0.5       ]\n",
      "  [0.24720322 0.5       ]\n",
      "  [0.47157604 0.5       ]]\n",
      "\n",
      " [[0.5112358  0.5       ]\n",
      "  [0.52274656 0.5       ]\n",
      "  [0.5526021  0.5       ]\n",
      "  ...\n",
      "  [0.24720322 0.5       ]\n",
      "  [0.47157604 0.5       ]\n",
      "  [0.4701507  0.5       ]]\n",
      "\n",
      " [[0.52274656 0.5       ]\n",
      "  [0.5526021  0.5       ]\n",
      "  [0.5594713  0.5       ]\n",
      "  ...\n",
      "  [0.47157604 0.5       ]\n",
      "  [0.4701507  0.5       ]\n",
      "  [0.5732524  0.5       ]]]\n",
      "(180, 2)\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Convert pd DataFrame or Series to np.array for using LSTM network implemented with TF/Keras\n",
    "# MinMax normalization for train X (from 0 to 1)\n",
    "cols_normalize =  ['temperature']\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "train_x_df['temp_norm'] = min_max_scaler.fit_transform(train_x_df[cols_normalize]).flatten()\n",
    "\n",
    "\n",
    "# MinMax normalization for test X (from 0 to 1)\n",
    "test_x_df['temp_norm'] = min_max_scaler.fit_transform(test_x_df[cols_normalize]).flatten()\n",
    "\n",
    "\n",
    "## Generate sequences and labels as for the input of the network\n",
    "# pick a large window size of 100 cycles (put in 100 minutes of time series data of temperature )\n",
    "sequence_length = 180\n",
    "\n",
    "\n",
    "\n",
    "# function to reshape features into (samples, time steps, features) \n",
    "def gen_sequence(train_df, seq_length, seq_cols):\n",
    "    \"\"\" Only sequences that meet the window-length are considered, no padding is used. This means for testing\n",
    "    we need to drop those which are below the window-length. An alternative would be to pad sequences so that\n",
    "    we can use shorter ones \n",
    "    \n",
    "    train_df: target dataframe (input time series data)\n",
    "    seq_length : sequence_length\n",
    "    seq_cols : feature(data) columns\n",
    "    \n",
    "    \"\"\"\n",
    "    # for one id I put all the rows in a single matrix\n",
    "    data_matrix = train_df[seq_cols].values\n",
    "    num_elements = data_matrix.shape[0]\n",
    "    # Iterate over two lists in parallel.\n",
    "    # For example id1 have 192 rows and sequence_length is equal to 50\n",
    "    # so zip iterate over two following list of numbers (0,112),(50,192)\n",
    "    # 0 50 -> from row 0 to row 50\n",
    "    # 1 51 -> from row 1 to row 51\n",
    "    # 2 52 -> from row 2 to row 52\n",
    "    # ...\n",
    "    # 111 191 -> from row 111 to 191\n",
    "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
    "        yield data_matrix[start:stop, :]\n",
    "        \n",
    "# pick the feature columns \n",
    "sequence_cols = ['temp_norm','pad']\n",
    "\n",
    "\n",
    "# generator for the sequences\n",
    "seq_gen = list(gen_sequence(train_x_df, sequence_length, sequence_cols)) \n",
    "\n",
    "\n",
    "# generate sequences and convert to numpy array\n",
    "# seq_array = np.concatenate(list(seq_gen)).astype(np.float32)\n",
    "seq_array = np.asarray(seq_gen, dtype=np.float32 )\n",
    "# shape: ( # of instances, sequence_length , # data sources(features)  )\n",
    "print (seq_array.shape)\n",
    "print (seq_array)\n",
    "print (seq_array[0].shape)\n",
    "\n",
    "\n",
    "\n",
    "# function to generate labels\n",
    "def gen_labels(y_df, seq_length, label):\n",
    "    '''\n",
    "    y_df : label dataframe\n",
    "    seq_length : sequence_length\n",
    "    label : binary label of each class\n",
    "    '''\n",
    "    data_matrix = y_df[label].values\n",
    "    num_elements = data_matrix.shape[0]\n",
    "    # I have to remove the first seq_length labels\n",
    "    # because for one id the first sequence of seq_length size have as target\n",
    "    # the last label (the previus ones are discarded).\n",
    "    # All the next id's sequences will have associated step by step one label as target. \n",
    "    return data_matrix[seq_length:num_elements, :]\n",
    "\n",
    "# generate labels\n",
    "label_gen_multi = gen_labels(train_y_df, sequence_length, \n",
    "                              ['label_abnormal(cold)', 'label_abnormal(hot)', 'label_normal']) \n",
    "label_array_train = np.asarray(label_gen_multi, dtype=np.float32 )\n",
    "\n",
    "label_array_train.shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nb_features = seq_array.shape[2]\n",
    "nb_out = label_array_train.shape[1]\n",
    "\n",
    "print (nb_features)\n",
    "print (nb_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 180, 180)          131760    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 180, 180)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 180, 120)          144480    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 180, 120)          0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 60)                43440     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 183       \n",
      "=================================================================\n",
      "Total params: 319,863\n",
      "Trainable params: 319,863\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 952992 samples, validate on 105888 samples\n",
      "Epoch 1/1\n",
      "169800/952992 [====>.........................] - ETA: 4:09:33 - loss: 0.4341 - acc: 0.8934"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a918243a01d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Do something with the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Model/LSTM_multi_model.h5'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a918243a01d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m     history = model.fit(seq_array, label_array_train, epochs=1, batch_size=bs, validation_split=0.1, verbose=1,\n\u001b[1;32m     67\u001b[0m               callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='min'),\n\u001b[0;32m---> 68\u001b[0;31m                            keras.callbacks.ModelCheckpoint(model_path,monitor='val_loss', save_best_only=True, mode='min', verbose=0)]\n\u001b[0m\u001b[1;32m     69\u001b[0m               )\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Next, we build a deep network. \n",
    "# The first layer is an LSTM layer with 100 units followed by another LSTM layer with 50 units. \n",
    "# Dropout is also applied after each LSTM layer to control overfitting. \n",
    "# Final layer is a Dense output layer with single unit and sigmoid activation since this is a binary classification problem.\n",
    "# build the network\n",
    "model_path = 'Model/LSTM_multi_model.h5'\n",
    "bs = 300\n",
    "\n",
    "\n",
    "try:\n",
    "    f = open(model_path)\n",
    "    # Do something with the file\n",
    "    print(\"Trained model already exists\")\n",
    "\n",
    "\n",
    "except IOError:\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # model.add(LSTM(\n",
    "    #          input_shape=(sequence_length, nb_features),\n",
    "    #          units=200,\n",
    "    #          return_sequences=True))\n",
    "    # model.add(Dropout(0.1))\n",
    "\n",
    "    # model.add(LSTM(\n",
    "    #          units=100,\n",
    "    #          return_sequences=True))\n",
    "    # model.add(Dropout(0.1))\n",
    "\n",
    "    # model.add(LSTM(\n",
    "    #           units=50,\n",
    "    #           return_sequences=False))\n",
    "    # model.add(Dropout(0.1))\n",
    "\n",
    "\n",
    "    model.add(LSTM(\n",
    "             input_shape=(sequence_length, nb_features),\n",
    "             units=180,\n",
    "             return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(LSTM(\n",
    "             units=120,\n",
    "             return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(LSTM(\n",
    "              units=60,\n",
    "              return_sequences=False))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Dense(units=nb_out, activation='softmax'))\n",
    "    adm = optimizers.Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=adm, loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "    # adm = optimizers.Adam(learning_rate=0.0001)\n",
    "    # keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "\n",
    "#     model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "    print(model.summary())\n",
    "\n",
    "\n",
    "    # fit the network\n",
    "    history = model.fit(seq_array, label_array_train, epochs=1, batch_size=bs, validation_split=0.1, verbose=1,\n",
    "              callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='min'),\n",
    "                           keras.callbacks.ModelCheckpoint(model_path,monitor='val_loss', save_best_only=True, mode='min', verbose=0)]\n",
    "              )\n",
    "\n",
    "    # list all data in history\n",
    "    print(history.history.keys())\n",
    "    \n",
    "    \n",
    "\n",
    "#     # summarize history for Accuracy\n",
    "#     fig_acc = plt.figure(figsize=(10, 10))\n",
    "#     plt.plot(history.history['acc'])\n",
    "#     plt.plot(history.history['val_acc'])\n",
    "#     plt.title('model accuracy')\n",
    "#     plt.ylabel('accuracy')\n",
    "#     plt.xlabel('epoch')\n",
    "#     plt.legend(['train', 'test'], loc='upper left')\n",
    "#     plt.show()\n",
    "#     fig_acc.savefig(\"Result/multi_model_accuracy.png\")\n",
    "\n",
    "#     # summarize history for Loss\n",
    "#     fig_acc = plt.figure(figsize=(10, 10))\n",
    "#     plt.plot(history.history['loss'])\n",
    "#     plt.plot(history.history['val_loss'])\n",
    "#     plt.title('model loss')\n",
    "#     plt.ylabel('loss')\n",
    "#     plt.xlabel('epoch')\n",
    "#     plt.legend(['train', 'test'], loc='upper left')\n",
    "#     plt.show()\n",
    "#     fig_acc.savefig(\"Result/multi_model_loss.png\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Evaluation\n",
    "'''\n",
    "# Define the function for plotting confusion matrix(cm)\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "\n",
    "    classes = classes\n",
    "\n",
    "    if normalize:\n",
    "\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print (\"check4\")\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    \n",
    "    plt.rcParams['figure.figsize'] = [15, 8]\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap, aspect='equal')\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    yt_ref = np.arange(cm.shape[0], dtype=np.float64)\n",
    "\n",
    "    print (\"yt_ref\", yt_ref)    \n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=yt_ref,\n",
    "           ylim = (2.5, -0.5),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "# Precision and label setting for cm and plotting\n",
    "np.set_printoptions(precision=2)\n",
    "labels = ['cold', 'hot', 'normal' ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Test and Evaluation\n",
    "'''\n",
    "# pick the feature columns \n",
    "sequence_cols = ['temp_norm','pad']\n",
    "\n",
    "# generator for the test sequences\n",
    "seq_gen_test = list(gen_sequence(test_x_df, sequence_length, sequence_cols)) \n",
    "# print (\"seq_gen_test\",seq_gen_test)\n",
    "# generate sequences and convert to numpy array\n",
    "seq_array_test = np.asarray(seq_gen_test, dtype=np.float32 )\n",
    "# shape: ( # of instances, sequence_length , # data sources(features)  )\n",
    "print (seq_array_test.shape)\n",
    "print (\"seq_array_test[0] \\n\", seq_array_test[0].shape)\n",
    "\n",
    "\n",
    "\n",
    "# generate labels\n",
    "label_gen_multi_test = gen_labels(test_truth_df, sequence_length, \n",
    "                              ['label_str']) \n",
    "label_array_test = np.asarray(label_gen_multi_test)\n",
    "\n",
    "print (label_array_test.shape)\n",
    "print (label_array_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if best iteration's model was saved then load and use it\n",
    "if os.path.isfile(model_path):\n",
    "    estimator = load_model(model_path)\n",
    "\n",
    "    \n",
    "\n",
    "# # test metrics\n",
    "# scores_test = estimator.evaluate(seq_array_test_last, label_array_test_last, verbose=2)\n",
    "# print('Accurracy: {}'.format(scores_test[1]))\n",
    "\n",
    "# make predictions and compute confusion matrix\n",
    "y_pred_test = estimator.predict_classes(seq_gen_test,verbose=1)\n",
    "y_true_test = label_array_test\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "test_print = pd.DataFrame()\n",
    "test_print['date'] = test_truth_df['date']\n",
    "test_print['y_pred']  = y_pred_test.flatten()\n",
    "test_print['y_truth'] = y_true_test.flatten()\n",
    "print (test_print)\n",
    "\n",
    "\n",
    "\n",
    "# test_set = pd.DataFrame(y_pred_test)\n",
    "# test_set.to_csv('Result/multi_submit_test.csv', index = None)\n",
    "\n",
    "# print('Confusion matrix\\n- x-axis is true labels.\\n- y-axis is predicted labels')\n",
    "# cm = confusion_matrix(y_true_test, y_pred_test)\n",
    "# print(cm)\n",
    "\n",
    "\n",
    "\n",
    "# # Plot non-normalized confusion matrix\n",
    "# plot_confusion_matrix(y_true_test, y_pred_test, classes=labels,\n",
    "#                       title='Confusion matrix, without normalization')\n",
    "\n",
    "# # Plot normalized confusion matrix\n",
    "# plot_confusion_matrix(y_true_test, y_pred_test, classes=labels, normalize=True,\n",
    "#                       title='Normalized confusion matrix')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# precision, recall, fscore, support = score(y_true_test, y_pred_test)\n",
    "\n",
    "# print('precision: {}'.format(precision))\n",
    "# print('recall: {}'.format(recall))\n",
    "# print('fscore: {}'.format(fscore))\n",
    "# print('support: {}'.format(support))\n",
    "\n",
    "\n",
    "# # compute precision and recall\n",
    "# # precision_test = precision_score(y_true_test, y_pred_test)\n",
    "# # recall_test = recall_score(y_true_test, y_pred_test)\n",
    "# # f1_test = 2 * (precision_test * recall_test) / (precision_test + recall_test)\n",
    "# # print( 'Precision: ', precision_test, '\\n', 'Recall: ', recall_test,'\\n', 'F1-score:', f1_test )\n",
    "\n",
    "# # Plot in blue color the predicted data and in green color the\n",
    "# # actual data to verify visually the accuracy of the model.\n",
    "# fig_verify = plt.figure(figsize=(10, 5))\n",
    "# plt.plot(y_pred_test, color=\"blue\")\n",
    "# plt.plot(y_true_test, color=\"green\")\n",
    "# plt.title('prediction')\n",
    "# plt.ylabel('state')\n",
    "# plt.xlabel('row')\n",
    "# plt.legend(['predicted', 'actual data'], loc='upper left')\n",
    "# plt.show()\n",
    "# fig_verify.savefig(\"Result/multi_model_verify.png\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluation\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, recall_score, accuracy_score, precision_score\n",
    "\n",
    "\n",
    "def Evaluate(predicted, actual, labels):\n",
    "    output_labels = []\n",
    "    output = []\n",
    "\n",
    "    # Calculate and display confusion matrix\n",
    "    cm = confusion_matrix(actual, predicted, labels=labels)\n",
    "    print('Confusion matrix\\n- x-axis is true labels (none, comp1, etc.)\\n- y-axis is predicted labels')\n",
    "    print(cm)\n",
    "\n",
    "    # Calculate precision, recall, and F1 score\n",
    "    accuracy = np.array([float(np.trace(cm)) / np.sum(cm)] * len(labels))\n",
    "    precision = precision_score(actual, predicted, average=None, labels=labels)\n",
    "    recall = recall_score(actual, predicted, average=None, labels=labels)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    output.extend([accuracy.tolist(), precision.tolist(), recall.tolist(), f1.tolist()])\n",
    "    output_labels.extend(['accuracy', 'precision', 'recall', 'F1'])\n",
    "\n",
    "    # Calculate the macro versions of these metrics\n",
    "    output.extend([[np.mean(precision)] * len(labels),\n",
    "                   [np.mean(recall)] * len(labels),\n",
    "                   [np.mean(f1)] * len(labels)])\n",
    "    output_labels.extend(['macro precision', 'macro recall', 'macro F1'])\n",
    "\n",
    "    # Find the one-vs.-all confusion matrix\n",
    "    cm_row_sums = cm.sum(axis=1)\n",
    "    cm_col_sums = cm.sum(axis=0)\n",
    "    s = np.zeros((2, 2))\n",
    "    for i in range(len(labels)):\n",
    "        v = np.array([[cm[i, i],\n",
    "                       cm_row_sums[i] - cm[i, i]],\n",
    "                      [cm_col_sums[i] - cm[i, i],\n",
    "                       np.sum(cm) + cm[i, i] - (cm_row_sums[i] + cm_col_sums[i])]])\n",
    "        s += v\n",
    "    s_row_sums = s.sum(axis=1)\n",
    "\n",
    "    # Add average accuracy and micro-averaged  precision/recall/F1\n",
    "    avg_accuracy = [np.trace(s) / np.sum(s)] * len(labels)\n",
    "    micro_prf = [float(s[0, 0]) / s_row_sums[0]] * len(labels)\n",
    "    output.extend([avg_accuracy, micro_prf])\n",
    "    output_labels.extend(['average accuracy',\n",
    "                          'micro-averaged precision/recall/F1'])\n",
    "\n",
    "    # Compute metrics for the majority classifier\n",
    "    mc_index = np.where(cm_row_sums == np.max(cm_row_sums))[0][0]\n",
    "    cm_row_dist = cm_row_sums / float(np.sum(cm))\n",
    "    mc_accuracy = 0 * cm_row_dist\n",
    "    mc_accuracy[mc_index] = cm_row_dist[mc_index]\n",
    "    mc_recall = 0 * cm_row_dist\n",
    "    mc_recall[mc_index] = 1\n",
    "    mc_precision = 0 * cm_row_dist\n",
    "    mc_precision[mc_index] = cm_row_dist[mc_index]\n",
    "    mc_F1 = 0 * cm_row_dist\n",
    "    mc_F1[mc_index] = 2 * mc_precision[mc_index] / (mc_precision[mc_index] + 1)\n",
    "    output.extend([mc_accuracy.tolist(), mc_recall.tolist(),\n",
    "                   mc_precision.tolist(), mc_F1.tolist()])\n",
    "    output_labels.extend(['majority class accuracy', 'majority class recall',\n",
    "                          'majority class precision', 'majority class F1'])\n",
    "\n",
    "    # Random accuracy and kappa\n",
    "    cm_col_dist = cm_col_sums / float(np.sum(cm))\n",
    "    exp_accuracy = np.array([np.sum(cm_row_dist * cm_col_dist)] * len(labels))\n",
    "    kappa = (accuracy - exp_accuracy) / (1 - exp_accuracy)\n",
    "    output.extend([exp_accuracy.tolist(), kappa.tolist()])\n",
    "    output_labels.extend(['expected accuracy', 'kappa'])\n",
    "\n",
    "    # Random guess\n",
    "    rg_accuracy = np.ones(len(labels)) / float(len(labels))\n",
    "    rg_precision = cm_row_dist\n",
    "    rg_recall = np.ones(len(labels)) / float(len(labels))\n",
    "    rg_F1 = 2 * cm_row_dist / (len(labels) * cm_row_dist + 1)\n",
    "    output.extend([rg_accuracy.tolist(), rg_precision.tolist(),\n",
    "                   rg_recall.tolist(), rg_F1.tolist()])\n",
    "    output_labels.extend(['random guess accuracy', 'random guess precision',\n",
    "                          'random guess recall', 'random guess F1'])\n",
    "\n",
    "    # Random weighted guess\n",
    "    rwg_accuracy = np.ones(len(labels)) * sum(cm_row_dist ** 2)\n",
    "    rwg_precision = cm_row_dist\n",
    "    rwg_recall = cm_row_dist\n",
    "    rwg_F1 = cm_row_dist\n",
    "    output.extend([rwg_accuracy.tolist(), rwg_precision.tolist(),\n",
    "                   rwg_recall.tolist(), rwg_F1.tolist()])\n",
    "    output_labels.extend(['random weighted guess accuracy',\n",
    "                          'random weighted guess precision',\n",
    "                          'random weighted guess recall',\n",
    "                          'random weighted guess F1'])\n",
    "\n",
    "    output_df = pd.DataFrame(output, columns=labels)\n",
    "    output_df.index = output_labels\n",
    "\n",
    "    return output_df\n",
    "\n",
    "\n",
    "# evaluation_results = []\n",
    "# for i, test_result in enumerate(test_results):\n",
    "#     print('\\nSplit %d:' % (i + 1))\n",
    "#     evaluation_result = Evaluate(actual=test_result['label'],\n",
    "#                                  predicted=test_result['predicted_state'],\n",
    "#                                  labels=['none', 'abnormal(cold)', 'abnormal(hot)'])\n",
    "#     evaluation_results.append(evaluation_result)\n",
    "# print (evaluation_results[0])  # show full results for first split only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Draw the barchart of component failing(ground trurh & prediction)\n",
    "plt.figure(figsize=(12, 6))\n",
    "counts_failures = test_print['y_truth'].value_counts().drop('normal')\n",
    "counts_pd_failures = test_print['y_pred'].value_counts().drop('normal')\n",
    "counts = pd.concat([counts_failures,counts_pd_failures],axis=1)\n",
    "# print (\"counts\", counts )\n",
    "sns.set_style(\"darkgrid\")\n",
    "ax = counts.plot(kind='bar', legend='true')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(14,7)\n",
    "plt.xlabel('Component failing')\n",
    "plt.ylabel('Count')\n",
    "plt.title(\"Barchart of component failing counts (ground trurh & prediction)\" , fontdict = {'fontsize':15, 'fontweight':'bold'})\n",
    "plt.savefig('Result/lstm_barchart_truth.png', bbox_inches='tight')\n",
    "\n",
    "\n",
    "## Draw the barchart of component failing(ground trurh)\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.figure(figsize=(14, 7))\n",
    "test_result['label'].value_counts().plot(kind='bar')\n",
    "plt.xlabel('Component failing')\n",
    "plt.ylabel('Count')\n",
    "plt.title(\"Barchart of component failing counts (without normal operation)\" , fontdict = {'fontsize':15, 'fontweight':'bold'})\n",
    "plt.savefig('Result/lstm_barchart_truth(w none).png', bbox_inches='tight')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
